{
  INDArray output=Nd4j.getExecutioner().execAndReturn(Nd4j.getOpFactory().createTransform(conf().getLayer().getActivationFunction(),preOut.dup()));
  INDArray outSubLabels=output.sub(getLabels2d());
  Gradient gradient=new DefaultGradient();
  if (maskArray != null) {
    outSubLabels.muliColumnVector(maskArray);
  }
  Triple<Gradient,INDArray,INDArray> triple;
switch (layerConf().getLossFunction()) {
case MCXENT:
    gradient.gradientForVariable().put(DefaultParamInitializer.WEIGHT_KEY,input.transpose().mmul(outSubLabels));
  gradient.gradientForVariable().put(DefaultParamInitializer.BIAS_KEY,outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
case XENT:
gradient.gradientForVariable().put(DefaultParamInitializer.WEIGHT_KEY,input.transpose().mmul(outSubLabels.div(output.mul(output.rsub(1)))));
gradient.gradientForVariable().put(DefaultParamInitializer.BIAS_KEY,outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
case MSE:
INDArray delta=outSubLabels.mul(derivativeActivation(preOut));
gradient.gradientForVariable().put(DefaultParamInitializer.WEIGHT_KEY,input.transpose().mmul(delta));
gradient.gradientForVariable().put(DefaultParamInitializer.BIAS_KEY,delta.sum(0));
triple=new Triple<>(gradient,delta,output);
break;
case EXPLL:
gradient.gradientForVariable().put(DefaultParamInitializer.WEIGHT_KEY,input.transpose().mmul(labels.rsub(1).divi(output)));
gradient.gradientForVariable().put(DefaultParamInitializer.BIAS_KEY,outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
case RMSE_XENT:
INDArray squaredrmseXentDiff=pow(outSubLabels,2.0);
INDArray sqrt=sqrt(squaredrmseXentDiff);
gradient.gradientForVariable().put(DefaultParamInitializer.WEIGHT_KEY,input.transpose().mmul(sqrt));
gradient.gradientForVariable().put(DefaultParamInitializer.BIAS_KEY,outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
case SQUARED_LOSS:
gradient.gradientForVariable().put(DefaultParamInitializer.WEIGHT_KEY,input.transpose().mmul(pow(outSubLabels,2)));
gradient.gradientForVariable().put(DefaultParamInitializer.BIAS_KEY,outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
case NEGATIVELOGLIKELIHOOD:
gradient.gradientForVariable().put(DefaultParamInitializer.WEIGHT_KEY,input.transpose().mmul(outSubLabels));
gradient.gradientForVariable().put(DefaultParamInitializer.BIAS_KEY,outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
default :
throw new IllegalStateException("Invalid loss function: " + layerConf().getLossFunction());
}
return triple;
}
