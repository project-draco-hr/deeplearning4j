{
  INDArray output=Nd4j.getExecutioner().execAndReturn(Nd4j.getOpFactory().createTransform(conf().getLayer().getActivationFunction(),preOut.dup()));
  INDArray outSubLabels=output.sub(getLabels2d());
  Gradient gradient=new DefaultGradient();
  INDArray weightGradView=gradientViews.get(DefaultParamInitializer.WEIGHT_KEY);
  INDArray biasGradView=gradientViews.get(DefaultParamInitializer.BIAS_KEY);
  gradient.gradientForVariable().put(DefaultParamInitializer.WEIGHT_KEY,weightGradView);
  gradient.gradientForVariable().put(DefaultParamInitializer.BIAS_KEY,biasGradView);
  if (maskArray != null) {
    outSubLabels.muliColumnVector(maskArray);
  }
  Triple<Gradient,INDArray,INDArray> triple;
switch (layerConf().getLossFunction()) {
case MCXENT:
    weightGradView.assign(input.transpose().mmul(outSubLabels));
  biasGradView.assign(outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
case XENT:
weightGradView.assign(input.transpose().mmul(outSubLabels.div(output.mul(output.rsub(1)))));
biasGradView.assign(outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
case MSE:
INDArray delta=outSubLabels.mul(derivativeActivation(preOut));
weightGradView.assign(input.transpose().mmul(delta));
biasGradView.assign(delta.sum(0));
triple=new Triple<>(gradient,delta,output);
break;
case EXPLL:
weightGradView.assign(input.transpose().mmul(labels.rsub(1).divi(output)));
biasGradView.assign(outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
case RMSE_XENT:
INDArray squaredrmseXentDiff=pow(outSubLabels,2.0);
INDArray sqrt=sqrt(squaredrmseXentDiff);
weightGradView.assign(input.transpose().mmul(sqrt));
biasGradView.assign(outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
case SQUARED_LOSS:
weightGradView.assign(input.transpose().mmul(pow(outSubLabels,2)));
biasGradView.assign(outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
case NEGATIVELOGLIKELIHOOD:
weightGradView.assign(input.transpose().mmul(outSubLabels));
biasGradView.assign(outSubLabels.sum(0));
triple=new Triple<>(gradient,outSubLabels,output);
break;
default :
throw new IllegalStateException("Invalid loss function: " + layerConf().getLossFunction());
}
return triple;
}
