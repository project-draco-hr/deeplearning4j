{
  MatrixUtil.ensureValidOutcomeMatrix(labels);
  DoubleMatrix layerInput=network.sigmoidLayers[network.sigmoidLayers.length - 1].sample_h_given_v();
  if (layerInput.rows != labels.rows) {
    log.info("Unable to train on labels; mismatching labels and rows. Did the layer input get initialized right?");
    return;
  }
  network.logLayer.input=layerInput;
  network.logLayer.labels=labels;
  DoubleMatrix w=network.logLayer.W.dup();
  DoubleMatrix b=network.logLayer.b.dup();
  Double currLoss=null;
  Integer numTimesOver=null;
  for (int i=0; i < epochs; i++) {
    network.logLayer.train(layerInput,labels,lr);
    lr*=network.learningRateUpdate;
    log.info("Negative log likelihood on epoch " + i + " "+ network.negativeLogLikelihood());
  }
  network.backProp(lr,epochs);
}
