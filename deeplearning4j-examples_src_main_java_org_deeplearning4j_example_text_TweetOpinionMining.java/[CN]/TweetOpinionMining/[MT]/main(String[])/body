{
  ClassPathResource resource=new ClassPathResource("/tweets_clean.txt");
  InputStream is=resource.getInputStream();
  LabelAwareListSentenceIterator iterator=new LabelAwareListSentenceIterator(is);
  iterator.setPreProcessor(new SentencePreProcessor(){
    @Override public String preProcess(    String sentence){
      return new InputHomogenization(sentence).transform();
    }
  }
);
  TokenizerFactory tokenizerFactory=new UimaTokenizerFactory();
  TextVectorizer vectorizor=new TfidfVectorizer(iterator,tokenizerFactory,Arrays.asList("0","1","2"),100);
  DataSet data=vectorizor.vectorize();
  data.binarize();
  log.info("Vocab " + vectorizor.vocab());
  DataSetIterator iter=new ListDataSetIterator(data.asList(),10);
  DBN dbn=new DBN.Builder().useAdaGrad(true).useRegularization(false).hiddenLayerSizes(new int[]{iter.inputColumns() / 2,iter.inputColumns() / 4,iter.inputColumns() / 6}).normalizeByInputRows(true).numberOfInputs(iter.inputColumns()).numberOfOutPuts(iter.totalOutcomes()).build();
  while (iter.hasNext()) {
    DataSet next=iter.next();
    dbn.pretrain(next.getFirst(),1,1e-1,10000);
  }
  iter.reset();
  while (iter.hasNext()) {
    DataSet next=iter.next();
    dbn.setInput(next.getFirst());
    dbn.finetune(next.getSecond(),1e-1,10000);
  }
  Evaluation eval=new Evaluation();
  eval.eval(data.getSecond(),dbn.predict(data.getFirst()));
  log.info(eval.stats());
  log.info("Example tweets " + data.numExamples());
}
