{
  InputStream is=FileUtils.openInputStream(new File(args[0]));
  LabelAwareSentenceIterator iterator=new LabelAwareListSentenceIterator(is);
  iterator.setPreProcessor(new SentencePreProcessor(){
    @Override public String preProcess(    String sentence){
      return new InputHomogenization(sentence).transform();
    }
  }
);
  TokenizerFactory tokenizerFactory=new UimaTokenizerFactory();
  TextVectorizer vectorizor=new TfidfVectorizer(iterator,tokenizerFactory,Arrays.asList("0","1"),2000);
  DataSet data=vectorizor.vectorize();
  data.binarize();
  SerializationUtils.saveObject(data,new File("tweet-data.ser"));
  log.info("Vocab " + vectorizor.vocab());
  DataSetIterator iter=new ListDataSetIterator(data.asList(),10);
  DBN dbn=new DBN.Builder().hiddenLayerSizes(new int[]{iter.inputColumns() / 2,iter.inputColumns() / 4,iter.inputColumns() / 6}).numberOfInputs(iter.inputColumns()).numberOfOutPuts(iter.totalOutcomes()).build();
  while (iter.hasNext()) {
    DataSet next=iter.next();
    dbn.pretrain(next.getFeatureMatrix(),1,1e-1f,10000);
  }
  iter.reset();
  while (iter.hasNext()) {
    DataSet next=iter.next();
    dbn.setInput(next.getFeatureMatrix());
    dbn.finetune(next.getLabels(),1e-1f,10000);
  }
  Evaluation eval=new Evaluation();
  eval.eval(data.getLabels(),dbn.output(data.getFeatureMatrix()));
  log.info(eval.stats());
  log.info("Example tweets " + data.numExamples());
}
