{
  Nd4j.getRandom().setSeed(12345);
  int timeSeriesLength=6;
  ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().graphBuilder().addInputs("in").addLayer("0",new org.deeplearning4j.nn.conf.layers.GravesLSTM.Builder().nIn(5).nOut(7).activation("tanh").weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,0.5)).build(),"in").addLayer("1",new org.deeplearning4j.nn.conf.layers.GravesLSTM.Builder().nIn(7).nOut(8).activation("tanh").weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,0.5)).build(),"0").addLayer("2",new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT).weightInit(WeightInit.DISTRIBUTION).nIn(8).nOut(4).activation("softmax").weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,0.5)).build(),"1").setOutputs("2").build();
  ComputationGraph graph=new ComputationGraph(conf);
  graph.init();
  INDArray input3d=Nd4j.rand(new int[]{3,5,timeSeriesLength});
  INDArray out3d=graph.rnnTimeStep(input3d)[0];
  assertArrayEquals(out3d.shape(),new int[]{3,4,timeSeriesLength});
  graph.rnnClearPreviousState();
  for (int i=0; i < timeSeriesLength; i++) {
    INDArray input2d=input3d.tensorAlongDimension(i,1,0);
    INDArray out2d=graph.rnnTimeStep(input2d)[0];
    assertArrayEquals(out2d.shape(),new int[]{3,4});
    INDArray expOut2d=out3d.tensorAlongDimension(i,1,0);
    assertEquals(out2d,expOut2d);
  }
  graph.rnnClearPreviousState();
  for (int i=0; i < timeSeriesLength; i++) {
    INDArray temp=Nd4j.create(new int[]{3,5,1});
    temp.tensorAlongDimension(0,1,0).assign(input3d.tensorAlongDimension(i,1,0));
    INDArray out3dSlice=graph.rnnTimeStep(temp)[0];
    assertArrayEquals(out3dSlice.shape(),new int[]{3,4,1});
    assertTrue(out3dSlice.tensorAlongDimension(0,1,0).equals(out3d.tensorAlongDimension(i,1,0)));
  }
}
