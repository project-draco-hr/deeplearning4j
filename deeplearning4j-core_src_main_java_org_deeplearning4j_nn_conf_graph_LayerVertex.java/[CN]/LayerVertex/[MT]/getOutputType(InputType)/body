{
  if (vertexInputs.length != 1) {
    throw new InvalidInputTypeException("LayerVertex expects exactly one input. Got: " + Arrays.toString(vertexInputs));
  }
  Layer layer=layerConf.getLayer();
  if (layer instanceof ConvolutionLayer || layer instanceof SubsamplingLayer) {
    InputType.InputTypeConvolutional afterPreProcessor;
    if (preProcessor != null) {
      if (preProcessor instanceof FeedForwardToCnnPreProcessor) {
        FeedForwardToCnnPreProcessor ffcnn=(FeedForwardToCnnPreProcessor)preProcessor;
        afterPreProcessor=(InputType.InputTypeConvolutional)InputType.convolutional(ffcnn.getNumChannels(),ffcnn.getInputWidth(),ffcnn.getInputHeight());
      }
 else       if (preProcessor instanceof RnnToCnnPreProcessor) {
        RnnToCnnPreProcessor rnncnn=(RnnToCnnPreProcessor)preProcessor;
        afterPreProcessor=(InputType.InputTypeConvolutional)InputType.convolutional(rnncnn.getNumChannels(),rnncnn.getInputWidth(),rnncnn.getInputHeight());
      }
 else {
        afterPreProcessor=(InputType.InputTypeConvolutional)vertexInputs[0];
      }
    }
 else {
      afterPreProcessor=(InputType.InputTypeConvolutional)vertexInputs[0];
    }
    int channelsOut;
    int[] kernel;
    int[] stride;
    int[] padding;
    if (layer instanceof ConvolutionLayer) {
      channelsOut=((ConvolutionLayer)layer).getNOut();
      kernel=((ConvolutionLayer)layer).getKernelSize();
      stride=((ConvolutionLayer)layer).getStride();
      padding=((ConvolutionLayer)layer).getPadding();
    }
 else {
      channelsOut=afterPreProcessor.getDepth();
      kernel=((SubsamplingLayer)layer).getKernelSize();
      stride=((SubsamplingLayer)layer).getStride();
      padding=((SubsamplingLayer)layer).getPadding();
    }
    int inWidth=afterPreProcessor.getWidth();
    int inHeight=afterPreProcessor.getHeight();
    if (kernel[0] > inWidth + padding[0] || kernel[1] > inHeight + padding[1]) {
      throw new InvalidInputTypeException("Invalid input: activations into layer are w=" + inWidth + ", h="+ inHeight+ " but kernel size is "+ Arrays.toString(kernel)+ " with padding "+ Arrays.toString(padding));
    }
    if ((inWidth - kernel[0] + 2 * padding[0]) % stride[0] != 0) {
      throw new InvalidInputTypeException("Invalid input/configuration: activations into layer are inputWidth=" + inWidth + ", widthPadding="+ padding[0]+ ", kernelWidth = "+ kernel[0]+ ", strideWidth = "+ stride[0]+ ". (inputWidth-kernelWidth+2*widthPadding)/strideWidth is not an integer");
    }
    if ((inHeight - kernel[1] + 2 * padding[1]) % stride[1] != 0) {
      throw new InvalidInputTypeException("Invalid input/configuration: activations into layer are inputHeight=" + inHeight + ", heightPadding="+ padding[1]+ ", kernelHeight = "+ kernel[1]+ ", strideHeight = "+ stride[1]+ ". (inputHeight-kernelHeight+2*heightPadding)/strideHeight is not an integer");
    }
    int outWidth=(inWidth - kernel[0] + 2 * padding[0]) / stride[0] + 1;
    int outHeight=(inHeight - kernel[1] + 2 * padding[1]) / stride[1] + 1;
    return InputType.convolutional(channelsOut,outWidth,outHeight);
  }
 else   if (layer instanceof BaseRecurrentLayer) {
    return InputType.recurrent();
  }
 else   if (layer instanceof FeedForwardLayer) {
    return InputType.feedForward();
  }
 else {
    return vertexInputs[0];
  }
}
