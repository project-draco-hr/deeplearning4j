{
  ClassPathResource resource=new ClassPathResource("raw_sentences.txt");
  SentenceIterator iter=new LineSentenceIterator(resource.getFile());
  iter.setPreProcessor(new SentencePreProcessor(){
    @Override public String preProcess(    String sentence){
      return sentence.toLowerCase();
    }
  }
);
  TokenizerFactory t=new DefaultTokenizerFactory();
  final EndingPreProcessor preProcessor=new EndingPreProcessor();
  t.setTokenPreProcessor(new TokenPreProcess(){
    @Override public String preProcess(    String token){
      token=token.toLowerCase();
      String base=preProcessor.preProcess(token);
      base=base.replaceAll("\\d","d");
      if (base.endsWith("ly") || base.endsWith("ing"))       System.out.println();
      return base;
    }
  }
);
  InMemoryLookupCache cache=new InMemoryLookupCache(100,false);
  Word2Vec vec=new Word2Vec.Builder().minWordFrequency(1).vocabCache(cache).iterations(5).learningRate(2.5e-2).iterate(iter).tokenizerFactory(t).build();
  vec.fit();
  double sim=vec.similarity("day","night");
  Collection<String> similar=vec.wordsNearest("day",10);
  System.out.println(similar);
  Tsne tsne=new Tsne.Builder().setMaxIter(200).learningRate(500).useAdaGrad(false).normalize(false).usePca(false).build();
  cache.plotVocab(tsne);
  InMemoryLookupCache.writeTsneFormat(vec,tsne.getY(),new File("coords.csv"));
  for (  VocabWord word : cache.vocabWords()) {
    System.out.println("Word " + word.getWord() + " codes "+ Arrays.toString(word.getCodes())+ " points "+ Arrays.toString(word.getPoints())+ " code length "+ word.getCodeLength()+ " word freq "+ word.getWordFrequency());
  }
}
