{
  Nd4j.MAX_ELEMENTS_PER_SLICE=Integer.MAX_VALUE;
  Nd4j.MAX_SLICES_TO_PRINT=Integer.MAX_VALUE;
  NeuralNetConfiguration conf=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).miniBatch(false).seed(123).iterations(1000).learningRate(1e-1).layer(new org.deeplearning4j.nn.conf.layers.OutputLayer.Builder().nIn(4).nOut(3).weightInit(WeightInit.XAVIER).updater(Updater.ADAGRAD).lossFunction(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD).activation("softmax").build()).build();
  int numParams=LayerFactories.getFactory(conf).initializer().numParams(conf,true);
  INDArray params=Nd4j.create(1,numParams);
  OutputLayer o=LayerFactories.getFactory(conf).create(conf,null,0,params);
  int numSamples=150;
  int batchSize=150;
  DataSetIterator iter=new IrisDataSetIterator(batchSize,numSamples);
  DataSet iris=iter.next();
  iris.normalizeZeroMeanZeroUnitVariance();
  o.setListeners(new ScoreIterationListener(1));
  SplitTestAndTrain t=iris.splitTestAndTrain(0.8);
  o.fit(t.getTrain());
  log.info("Evaluate model....");
  Evaluation eval=new Evaluation(3);
  eval.eval(t.getTest().getLabels(),o.output(t.getTest().getFeatureMatrix(),true));
  log.info(eval.stats());
}
