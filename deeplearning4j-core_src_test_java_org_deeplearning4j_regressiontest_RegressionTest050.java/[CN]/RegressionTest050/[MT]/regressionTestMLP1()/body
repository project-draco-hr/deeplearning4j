{
  File f=new ClassPathResource("regression_testing/050/050_ModelSerializer_Regression_MLP_1.zip").getTempFileFromArchive();
  MultiLayerNetwork net=ModelSerializer.restoreMultiLayerNetwork(f,true);
  MultiLayerConfiguration conf=net.getLayerWiseConfigurations();
  assertEquals(2,conf.getConfs().size());
  assertTrue(conf.isBackprop());
  assertFalse(conf.isPretrain());
  DenseLayer l0=(DenseLayer)conf.getConf(0).getLayer();
  assertEquals("relu",l0.getActivationFunction());
  assertEquals(3,l0.getNIn());
  assertEquals(4,l0.getNOut());
  assertEquals(WeightInit.XAVIER,l0.getWeightInit());
  assertEquals(Updater.NESTEROVS,l0.getUpdater());
  assertEquals(0.9,l0.getMomentum(),1e-6);
  assertEquals(0.15,l0.getLearningRate(),1e-6);
  OutputLayer l1=(OutputLayer)conf.getConf(1).getLayer();
  assertEquals("softmax",l1.getActivationFunction());
  assertEquals(LossFunctions.LossFunction.MCXENT,l1.getLossFunction());
  assertEquals(4,l1.getNIn());
  assertEquals(5,l1.getNOut());
  assertEquals(WeightInit.XAVIER,l1.getWeightInit());
  assertEquals(Updater.NESTEROVS,l1.getUpdater());
  assertEquals(0.9,l1.getMomentum(),1e-6);
  assertEquals(0.15,l1.getLearningRate(),1e-6);
  int numParams=net.numParams();
  assertEquals(Nd4j.linspace(1,numParams,numParams),net.params());
  int updaterSize=net.getUpdater().stateSizeForLayer(net);
  assertEquals(Nd4j.linspace(1,updaterSize,updaterSize),net.getUpdater().getStateViewArray());
}
