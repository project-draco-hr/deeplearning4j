{
  Nd4j.getRandom().setSeed(12345);
  ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().seed(12345).optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).updater(Updater.NONE).learningRate(1.0).graphBuilder().addInputs("input").setOutputs("out").addLayer("lstm1",new GravesLSTM.Builder().nIn(3).nOut(4).activation("tanh").build(),"input").addVertex("lastTS",new LastTimeStepVertex("input"),"lstm1").addLayer("out",new OutputLayer.Builder().nIn(4).nOut(3).activation("softmax").lossFunction(LossFunctions.LossFunction.MCXENT).build(),"lastTS").pretrain(false).backprop(true).build();
  ComputationGraph graph=new ComputationGraph(conf);
  graph.init();
  Random r=new Random(12345);
  INDArray input=Nd4j.rand(new int[]{3,3,5});
  INDArray labels=Nd4j.zeros(3,3);
  for (int i=0; i < 3; i++) {
    labels.putScalar(new int[]{i,r.nextInt(3)},1.0);
  }
  if (PRINT_RESULTS) {
    System.out.println("testLSTMWithLastTimeStepVertex()");
    for (int j=0; j < graph.getNumLayers(); j++)     System.out.println("Layer " + j + " # params: "+ graph.getLayer(j).numParams());
  }
  boolean gradOK=GradientCheckUtil.checkGradients(graph,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,new INDArray[]{input},new INDArray[]{labels});
  String msg="testLSTMWithLastTimeStepVertex()";
  assertTrue(msg,gradOK);
  INDArray inMask=Nd4j.zeros(3,5);
  inMask.putRow(0,Nd4j.create(new double[]{1,1,1,0,0}));
  inMask.putRow(1,Nd4j.create(new double[]{1,1,1,1,0}));
  inMask.putRow(2,Nd4j.create(new double[]{1,1,1,1,1}));
  graph.setLayerMaskArrays(new INDArray[]{inMask},null);
  gradOK=GradientCheckUtil.checkGradients(graph,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,new INDArray[]{input},new INDArray[]{labels});
  assertTrue(msg,gradOK);
}
