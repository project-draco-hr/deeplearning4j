{
  Nd4j.getRandom().setSeed(12345);
  ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().seed(12345).optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).updater(Updater.NONE).learningRate(1.0).graphBuilder().addInputs("input").setOutputs("out").addLayer("lstm1",new GravesLSTM.Builder().nIn(3).nOut(4).activation("tanh").build(),"input").addLayer("lstm2",new GravesLSTM.Builder().nIn(4).nOut(4).activation("tanh").build(),"lstm1").addLayer("dense1",new DenseLayer.Builder().nIn(4).nOut(4).activation("sigmoid").build(),"lstm1").addLayer("lstm3",new GravesLSTM.Builder().nIn(4).nOut(4).activation("tanh").build(),"dense1").addNode("merge",new MergeVertex(),"lstm2","lstm3").addLayer("out",new RnnOutputLayer.Builder().nIn(8).nOut(3).activation("softmax").lossFunction(LossFunctions.LossFunction.MCXENT).build(),"merge").inputPreProcessor("dense1",new RnnToFeedForwardPreProcessor()).inputPreProcessor("lstm3",new FeedForwardToRnnPreProcessor()).pretrain(false).backprop(true).build();
  ComputationGraph graph=new ComputationGraph(conf);
  graph.init();
  Random r=new Random(12345);
  INDArray input=Nd4j.rand(new int[]{3,3,5});
  INDArray labels=Nd4j.zeros(3,3,5);
  for (int i=0; i < 3; i++) {
    for (int j=0; j < 5; j++) {
      labels.putScalar(new int[]{i,r.nextInt(3),j},1.0);
    }
  }
  if (PRINT_RESULTS) {
    System.out.println("testLSTMWithMerging()");
    for (int j=0; j < graph.getNumLayers(); j++)     System.out.println("Layer " + j + " # params: "+ graph.getLayer(j).numParams());
  }
  boolean gradOK=GradientCheckUtil.checkGradients(graph,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,new INDArray[]{input},new INDArray[]{labels});
  String msg="testLSTMWithMerging()";
  assertTrue(msg,gradOK);
}
