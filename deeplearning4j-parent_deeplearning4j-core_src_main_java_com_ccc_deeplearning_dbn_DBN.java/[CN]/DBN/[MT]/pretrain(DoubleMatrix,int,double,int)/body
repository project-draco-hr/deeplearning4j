{
  if (this.input == null) {
    this.input=input;
    initializeLayers(input);
  }
 else   this.input=input;
  DoubleMatrix layerInput=null;
  for (int i=0; i < nLayers; i++) {
    if (i == 0)     layerInput=this.input;
 else     layerInput=sigmoidLayers[i - 1].sampleHGivenV(layerInput);
    log.info("Training on layer " + (i + 1));
    Integer numTimesOver=1;
    Double bestLoss=Double.POSITIVE_INFINITY;
    DoubleMatrix bestWeights=layers[i].getW();
    DoubleMatrix bestHBias=layers[i].gethBias();
    DoubleMatrix bestVbias=layers[i].getvBias();
    for (int epoch=0; epoch < epochs; epoch++) {
      boolean trainedProperly=this.trainNetwork(layers[i],sigmoidLayers[i],epoch,i,layerInput,learningRate,bestLoss,new Object[]{k});
      if (!trainedProperly)       numTimesOver++;
 else {
        bestLoss=layers[i].getReConstructionCrossEntropy();
        bestWeights=layers[i].getW();
        bestHBias=layers[i].gethBias();
        bestVbias=layers[i].getvBias();
      }
      if (numTimesOver >= 30) {
        log.info("Breaking early; " + numTimesOver);
        layers[i].setW(bestWeights);
        layers[i].sethBias(bestHBias);
        layers[i].setvBias(bestVbias);
        break;
      }
    }
  }
}
