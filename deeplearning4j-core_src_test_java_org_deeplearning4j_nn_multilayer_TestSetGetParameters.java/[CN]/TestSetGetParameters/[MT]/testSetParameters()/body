{
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().list().layer(0,new DenseLayer.Builder().nIn(9).nOut(10).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).build()).layer(1,new RBM.Builder().nIn(10).nOut(11).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).build()).layer(2,new AutoEncoder.Builder().corruptionLevel(0.5).nIn(11).nOut(12).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).build()).layer(3,new OutputLayer.Builder(LossFunction.MSE).nIn(12).nOut(12).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).build()).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  net.init();
  INDArray initParams=net.params().dup();
  Map<String,INDArray> initParams2=net.paramTable();
  net.setParams(net.params());
  INDArray initParamsAfter=net.params();
  Map<String,INDArray> initParams2After=net.paramTable();
  for (  String s : initParams2.keySet()) {
    assertTrue("Params differ: " + s,initParams2.get(s).equals(initParams2After.get(s)));
  }
  assertEquals(initParams,initParamsAfter);
  INDArray randomParams=Nd4j.rand(initParams.shape());
  net.setParams(randomParams.dup());
  assertEquals(net.params(),randomParams);
}
