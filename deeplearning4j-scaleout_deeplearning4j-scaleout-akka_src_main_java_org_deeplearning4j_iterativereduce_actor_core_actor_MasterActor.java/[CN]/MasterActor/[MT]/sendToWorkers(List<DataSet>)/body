{
  Collection<WorkerState> workers=stateTracker.currentWorkers().values();
  int split=workers.size();
  final List<List<DataSet>> splitList=Lists.partition(datasets,split);
  partition=splitList.size();
  if (splitList.size() < workers.size()) {
    log.warning("You may want to reconfigure your batch sizes, the current partition rate does not match the number of available workers");
  }
  log.info("Found partition of size " + partition);
  for (int i=0; i < splitList.size(); i++) {
    final int j=i;
    Future<Void> f=Futures.future(new Callable<Void>(){
      @Override public Void call() throws Exception {
        log.info("Sending off work for batch " + j);
        WorkerState state=nextAvailableWorker();
        List<DataSet> work=new ArrayList<>(splitList.get(j));
        Job j2=new Job(state.getWorkerId(),(Serializable)work,pretrain);
        stateTracker.addJobToCurrent(j2);
        mediator.tell(new DistributedPubSubMediator.Publish(state.getWorkerId(),j2),getSelf());
        log.info("Delegated work to worker " + state.getWorkerId());
        state.setAvailable(false);
        return null;
      }
    }
,context().dispatcher());
    ActorRefUtils.throwExceptionIfExists(f,context().dispatcher());
  }
}
