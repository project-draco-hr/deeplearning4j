{
  File inputFile=new ClassPathResource("big/raw_sentences.txt").getFile();
  SentenceIterator iter=UimaSentenceIterator.createWithPath(inputFile.getAbsolutePath());
  TokenizerFactory t=new DefaultTokenizerFactory();
  t.setTokenPreProcessor(new CommonPreprocessor());
  VocabCache<VocabWord> cache=new AbstractCache.Builder<VocabWord>().build();
  SentenceTransformer transformer=new SentenceTransformer.Builder().iterator(iter).tokenizerFactory(t).build();
  AbstractSequenceIterator<VocabWord> sequenceIterator=new AbstractSequenceIterator.Builder<VocabWord>(transformer).build();
  VocabConstructor<VocabWord> constructor=new VocabConstructor.Builder<VocabWord>().addSource(sequenceIterator,5).useAdaGrad(false).setTargetVocabCache(cache).build();
  constructor.buildJointVocabulary(false,true);
  assertEquals(241,cache.numWords());
  assertEquals("i",cache.wordAtIndex(1));
  assertEquals("it",cache.wordAtIndex(0));
  assertEquals(634061,cache.totalWordOccurrences());
}
