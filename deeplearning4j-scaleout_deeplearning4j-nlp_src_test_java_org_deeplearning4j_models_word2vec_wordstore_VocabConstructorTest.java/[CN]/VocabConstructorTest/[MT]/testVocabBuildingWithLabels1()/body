{
  File inputFile=new ClassPathResource("/big/raw_sentences.txt").getFile();
  SentenceIterator iter=UimaSentenceIterator.createWithPath(inputFile.getAbsolutePath());
  TokenizerFactory t=new DefaultTokenizerFactory();
  t.setTokenPreProcessor(new CommonPreprocessor());
  LabelsSource generator=new LabelsSource("SNTX_");
  VocabConstructor<VocabWord> constructor=new VocabConstructor.Builder<VocabWord>().addSource(new SentenceIteratorConverter(iter,generator),5).useAdaGrad(false).fetchLabels(true).build();
  VocabCache cache=constructor.buildJointVocabulary(false,true);
  log.info("Total words in vocab: [" + cache.numWords() + "], Total word occurencies: ["+ cache.totalWordOccurrences()+ "]");
  assertEquals(97168,generator.getLabels().size());
  assertEquals(97410,cache.numWords());
  assertEquals(634061,cache.totalWordOccurrences());
  assertTrue(cache.containsWord("SNTX_8"));
  assertEquals(1,cache.wordFrequency("SNTX_8"));
}
