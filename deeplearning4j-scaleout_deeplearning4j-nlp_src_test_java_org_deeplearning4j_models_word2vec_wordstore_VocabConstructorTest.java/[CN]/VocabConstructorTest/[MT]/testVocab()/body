{
  File inputFile=new ClassPathResource("big/raw_sentences.txt").getFile();
  SentenceIterator iter=new BasicLineIterator(inputFile);
  Set<String> set=new HashSet<>();
  int lines=0;
  int cnt=0;
  while (iter.hasNext()) {
    Tokenizer tok=t.create(iter.nextSentence());
    for (    String token : tok.getTokens()) {
      if (token == null || token.isEmpty() || token.trim().isEmpty())       continue;
      cnt++;
      if (!set.contains(token))       set.add(token);
    }
    lines++;
  }
  log.info("Total number of tokens: [" + cnt + "], lines: ["+ lines+ "], set size: ["+ set.size()+ "]");
  log.info("Set:\n" + set);
}
