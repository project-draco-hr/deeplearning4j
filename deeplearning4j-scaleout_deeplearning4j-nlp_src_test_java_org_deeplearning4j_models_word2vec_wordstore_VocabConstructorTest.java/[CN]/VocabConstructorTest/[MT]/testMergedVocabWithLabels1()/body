{
  AbstractCache<VocabWord> cacheSource=new AbstractCache.Builder<VocabWord>().build();
  AbstractCache<VocabWord> cacheTarget=new AbstractCache.Builder<VocabWord>().build();
  ClassPathResource resource=new ClassPathResource("big/raw_sentences.txt");
  BasicLineIterator underlyingIterator=new BasicLineIterator(resource.getFile());
  SentenceTransformer transformer=new SentenceTransformer.Builder().iterator(underlyingIterator).tokenizerFactory(t).build();
  AbstractSequenceIterator<VocabWord> sequenceIterator=new AbstractSequenceIterator.Builder<VocabWord>(transformer).build();
  VocabConstructor<VocabWord> vocabConstructor=new VocabConstructor.Builder<VocabWord>().addSource(sequenceIterator,1).setTargetVocabCache(cacheSource).build();
  vocabConstructor.buildJointVocabulary(false,true);
  int sourceSize=cacheSource.numWords();
  log.info("Source Vocab size: " + sourceSize);
  FileLabelAwareIterator labelAwareIterator=new FileLabelAwareIterator.Builder().addSourceFolder(new ClassPathResource("/paravec/labeled").getFile()).build();
  transformer=new SentenceTransformer.Builder().iterator(labelAwareIterator).tokenizerFactory(t).build();
  sequenceIterator=new AbstractSequenceIterator.Builder<VocabWord>(transformer).build();
  VocabConstructor<VocabWord> vocabTransfer=new VocabConstructor.Builder<VocabWord>().addSource(sequenceIterator,1).setTargetVocabCache(cacheTarget).build();
  vocabTransfer.buildMergedVocabulary(cacheSource,true);
  assertEquals(sourceSize + 3,cacheTarget.numWords());
  assertEquals(cacheSource.wordAtIndex(17),cacheTarget.wordAtIndex(17));
  assertEquals(cacheSource.wordAtIndex(45),cacheTarget.wordAtIndex(45));
  assertEquals(cacheSource.wordAtIndex(89),cacheTarget.wordAtIndex(89));
  assertTrue(cacheTarget.indexOf("finance") > sourceSize - 1);
  assertTrue(cacheTarget.indexOf("science") > sourceSize - 1);
  assertTrue(cacheTarget.indexOf("health") > sourceSize - 1);
}
