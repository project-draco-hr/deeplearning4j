{
  File inputFile=new ClassPathResource("big/raw_sentences.txt").getFile();
  SentenceIterator iter=new BasicLineIterator(inputFile);
  TokenizerFactory t=new DefaultTokenizerFactory();
  t.setTokenPreProcessor(new CommonPreprocessor());
  VocabCache<VocabWord> cache=new AbstractCache.Builder<VocabWord>().build();
  SentenceTransformer transformer=new SentenceTransformer.Builder().iterator(iter).tokenizerFactory(t).build();
  AbstractSequenceIterator<VocabWord> sequenceIterator=new AbstractSequenceIterator.Builder<VocabWord>(transformer).build();
  VocabConstructor<VocabWord> constructor=new VocabConstructor.Builder<VocabWord>().addSource(sequenceIterator,0).useAdaGrad(false).setTargetVocabCache(cache).build();
  constructor.buildJointVocabulary(true,false);
  assertEquals(244,cache.numWords());
  assertEquals(0,cache.totalWordOccurrences());
}
