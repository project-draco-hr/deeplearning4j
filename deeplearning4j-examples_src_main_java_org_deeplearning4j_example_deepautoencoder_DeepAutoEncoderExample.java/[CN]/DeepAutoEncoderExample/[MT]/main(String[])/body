{
  DataSetIterator iter=new MnistDataSetIterator(10,10,false);
  int codeLayer=7;
  Map<Integer,Double> layerLearningRates=new HashMap<>();
  layerLearningRates.put(codeLayer,1e-2);
  RandomGenerator rng=new MersenneTwister(123);
  DBN dbn=new DBN.Builder().learningRateForLayer(layerLearningRates).hiddenLayerSizes(new int[]{500,250,100,50,25,10}).withRng(rng).useRBMPropUpAsActivation(true).withDist(Distributions.normal(rng,0.1)).activateForLayer(Collections.singletonMap(3,Activations.sigmoid())).withHiddenUnitsByLayer(Collections.singletonMap(codeLayer,RBM.HiddenUnit.GAUSSIAN)).numberOfInputs(784).lossFunctionByLayer(Collections.singletonMap(codeLayer,NeuralNetwork.LossFunction.RECONSTRUCTION_CROSSENTROPY)).sampleFromHiddenActivations(true).useRegularization(true).withL2(2e-3).numberOfOutPuts(784).withMomentum(0.5).momentumAfter(Collections.singletonMap(10,0.9)).build();
  log.info("Training with layers of " + RBMUtil.architecture(dbn));
  log.info("Begin training ");
  while (iter.hasNext()) {
    DataSet next=iter.next();
    dbn.pretrain(next.getFirst(),1,1e-1,150);
  }
  DeepAutoEncoder encoder=new DeepAutoEncoder.Builder().withEncoder(dbn).build();
  iter.reset();
  while (iter.hasNext()) {
    DataSet data=iter.next();
    for (int i=0; i < 10; i++)     encoder.finetune(data.getFirst(),1e-2,100);
  }
  iter.reset();
  while (iter.hasNext()) {
    DataSet data=iter.next();
    DeepAutoEncoderDataSetReconstructionRender r=new DeepAutoEncoderDataSetReconstructionRender(data.iterator(data.numExamples()),encoder,28,28);
    r.setPicDraw(MatrixTransformations.multiplyScalar(255));
    r.draw();
  }
}
