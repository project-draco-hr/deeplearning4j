{
  DataSetIterator iter=new MnistDataSetIterator(100,100,false);
  DBN dbn=new DBN.Builder().learningRateForLayer(Collections.singletonMap(3,1e-1)).withLossFunction(NeuralNetwork.LossFunction.RECONSTRUCTION_CROSSENTROPY).withOutputLossFunction(OutputLayer.LossFunction.RMSE_XENT).hiddenLayerSizes(new int[]{1000,500,250,28}).withHiddenUnitsByLayer(Collections.singletonMap(3,RBM.HiddenUnit.GAUSSIAN)).withOptimizationAlgorithm(NeuralNetwork.OptimizationAlgorithm.GRADIENT_DESCENT).numberOfInputs(784).withMomentum(0.9).withDropOut(0.5).useRegularization(true).withL2(2e-4).numberOfOutPuts(2).build();
  log.info("Training with layers of " + RBMUtil.architecure(dbn));
  for (int i=0; i < 5; i++) {
    while (iter.hasNext()) {
      DataSet data=iter.next();
      data.scale();
      dbn.pretrain(data.getFirst(),new Object[]{1,1e-1,10});
    }
    iter.reset();
  }
  DeepAutoEncoder encoder=new DeepAutoEncoder(dbn);
  encoder.setRoundCodeLayerInput(true);
  encoder.setUseHiddenActivationsForwardProp(false);
  encoder.setOutputLayerLossFunction(OutputLayer.LossFunction.XENT);
  for (int i=0; i < 100; i++) {
    while (iter.hasNext()) {
      DataSet next=iter.next();
      next.scale();
      log.info("Fine tune " + next.labelDistribution());
      encoder.finetune(next.getFirst(),1e-2,1000);
    }
    iter.reset();
  }
  while (iter.hasNext()) {
    DataSet data=iter.next();
    FilterRenderer f=new FilterRenderer();
    f.renderFilters(encoder.getOutputLayer().getW(),"outputlayer.png",28,28,data.numExamples());
    DeepAutoEncoderDataSetReconstructionRender r=new DeepAutoEncoderDataSetReconstructionRender(data.iterator(data.numExamples()),encoder);
    r.draw();
  }
}
