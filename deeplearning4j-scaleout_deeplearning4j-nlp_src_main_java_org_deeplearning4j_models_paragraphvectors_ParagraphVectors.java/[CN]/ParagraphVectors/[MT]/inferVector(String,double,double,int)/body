{
  if (tokenizerFactory == null)   throw new IllegalStateException("TokenizerFactory should be defined, prior to predict() call");
  List<String> tokens=tokenizerFactory.create(text).getTokens();
  List<VocabWord> document=new ArrayList<>();
  for (  String token : tokens) {
    if (vocab.containsWord(token)) {
      document.add(vocab.wordFor(token));
    }
  }
  return inferVector(document,learningRate,minLearningRate,iterations);
}
