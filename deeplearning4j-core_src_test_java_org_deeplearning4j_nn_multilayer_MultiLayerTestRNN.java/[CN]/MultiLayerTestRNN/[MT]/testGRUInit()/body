{
  int nIn=8;
  int nOut=25;
  int nHiddenUnits=17;
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().list(2).layer(0,new org.deeplearning4j.nn.conf.layers.GRU.Builder().nIn(nIn).nOut(nHiddenUnits).weightInit(WeightInit.DISTRIBUTION).build()).layer(1,new OutputLayer.Builder(LossFunctions.LossFunction.SQUARED_LOSS).nIn(nHiddenUnits).nOut(nOut).weightInit(WeightInit.DISTRIBUTION).build()).build();
  MultiLayerNetwork network=new MultiLayerNetwork(conf);
  network.init();
  Layer layer=network.getLayer(0);
  assertTrue(layer instanceof GRU);
  Map<String,INDArray> paramTable=layer.paramTable();
  assertTrue(paramTable.size() == 3);
  INDArray recurrentWeights=paramTable.get(GRUParamInitializer.RECURRENT_WEIGHT_KEY);
  assertArrayEquals(recurrentWeights.shape(),new int[]{nHiddenUnits,3 * nHiddenUnits});
  INDArray inputWeights=paramTable.get(GRUParamInitializer.INPUT_WEIGHT_KEY);
  assertArrayEquals(inputWeights.shape(),new int[]{nIn,3 * nHiddenUnits});
  INDArray biases=paramTable.get(GRUParamInitializer.BIAS_KEY);
  assertArrayEquals(biases.shape(),new int[]{1,3 * nHiddenUnits});
  int nParams=recurrentWeights.length() + inputWeights.length() + biases.length();
  assertTrue(nParams == layer.numParams());
}
