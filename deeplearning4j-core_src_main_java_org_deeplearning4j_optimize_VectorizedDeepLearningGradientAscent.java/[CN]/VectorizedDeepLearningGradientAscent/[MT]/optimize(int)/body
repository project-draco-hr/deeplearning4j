{
  int iterations;
  double fret;
  double fp=optimizable.getValue();
  DoubleMatrix xi=optimizable.getValueGradient();
  for (iterations=0; iterations < numIterations; iterations++) {
    logger.info("At iteration " + iterations + ", cost = "+ fp+ ", scaled = "+ maxStep+ " step = "+ step+ ", gradient infty-norm = "+ xi.normmax());
    double sum=xi.norm2();
    if (sum > stpmax) {
      logger.info("*** Step 2-norm " + sum + " greater than max "+ stpmax+ "  Scaling...");
      xi.muli(stpmax / sum);
    }
    try {
      step=lineMaximizer.optimize(xi,step);
    }
 catch (    Exception e) {
      logger.warn("Error during computation",e);
      continue;
    }
    fret=optimizable.getValue();
    if (2.0 * Math.abs(fret - fp) <= tolerance * (Math.abs(fret) + Math.abs(fp) + eps)) {
      logger.info("Gradient Ascent: Value difference " + Math.abs(fret - fp) + " below "+ "tolerance; saying converged.");
      converged=true;
      if (listener != null) {
        listener.epochDone(iterations);
      }
      return true;
    }
    fp=fret;
    xi=optimizable.getValueGradient();
    if (listener != null) {
      listener.epochDone(iterations);
    }
  }
  return false;
}
