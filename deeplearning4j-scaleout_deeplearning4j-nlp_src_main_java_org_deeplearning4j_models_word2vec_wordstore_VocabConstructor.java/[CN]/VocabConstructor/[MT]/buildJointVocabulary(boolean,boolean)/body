{
  if (resetCounters && buildHuffmanTree)   throw new IllegalStateException("You can't reset counters and build Huffman tree at the same time!");
  if (cache == null)   cache=new AbstractCache.Builder<T>().build();
  AbstractCache<T> topHolder=new AbstractCache.Builder<T>().minElementFrequency(0).build();
  int cnt=0;
  for (  VocabSource<T> source : sources) {
    SequenceIterator<T> iterator=source.getIterator();
    iterator.reset();
    log.info("Trying source iterator: [" + cnt + "]");
    cnt++;
    AbstractCache<T> tempHolder=new AbstractCache.Builder<T>().build();
    while (iterator.hasMoreSequences()) {
      Sequence<T> document=iterator.nextSequence();
      if (fetchLabels) {
        T labelWord=createInstance();
        labelWord.setSpecial(true);
        labelWord.setElementFrequency(1);
        tempHolder.addToken(labelWord);
      }
      List<String> tokens=document.asLabels();
      for (      String token : tokens) {
        if (stopWords != null && stopWords.contains(token))         continue;
        if (token == null || token.isEmpty())         continue;
        if (!tempHolder.containsWord(token)) {
          tempHolder.addToken(document.getElementByLabel(token));
        }
 else {
          tempHolder.incrementWordCount(token);
        }
      }
    }
    log.info("Vocab size before truncation: " + tempHolder.numWords());
    log.info("Vocab size after truncation: " + tempHolder.numWords());
    topHolder.importVocabulary(tempHolder);
  }
  if (resetCounters) {
    for (    T element : topHolder.vocabWords()) {
      element.setElementFrequency(0);
    }
    topHolder.updateWordsOccurencies();
    ;
  }
  if (buildHuffmanTree) {
    Huffman huffman=new Huffman(topHolder.vocabWords());
    huffman.build();
    huffman.applyIndexes(topHolder);
  }
  cache.importVocabulary(topHolder);
  return cache;
}
