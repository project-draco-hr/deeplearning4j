{
  if (resetCounters && buildHuffmanTree)   throw new IllegalStateException("You can't reset counters and build Huffman tree at the same time!");
  if (cache == null)   cache=new AbstractCache.Builder<T>().build();
  AbstractCache<T> topHolder=new AbstractCache.Builder<T>().minElementFrequency(0).build();
  for (  VocabSource source : sources) {
    SequenceIterator<T> iterator=source.getIterator();
    iterator.reset();
    AbstractCache<T> tempHolder=new AbstractCache.Builder<T>().build();
    while (iterator.hasMoreSequences()) {
      Sequence<T> document=iterator.nextSequence();
      if (fetchLabels) {
        T labelWord=createInstance();
        labelWord.setSpecial(true);
        labelWord.setElementFrequency(1);
        tempHolder.addToken(labelWord);
      }
      List<String> tokens=document.asLabels();
      for (      String token : tokens) {
        if (stopWords != null && stopWords.contains(token))         continue;
        if (token == null || token.isEmpty())         continue;
        if (!tempHolder.containsWord(token)) {
          tempHolder.addToken(document.getElementByLabel(token));
        }
 else {
          tempHolder.incrementWordCount(token);
        }
      }
    }
    log.info("Vocab size before truncation: " + tempHolder.numWords());
    log.info("Vocab size after truncation: " + tempHolder.numWords());
    topHolder.consumeVocabulary(tempHolder);
  }
  if (resetCounters)   topHolder.resetWordCounters();
  if (buildHuffmanTree)   topHolder.updateHuffmanCodes();
  topHolder.transferBackToVocabCache(cache);
  return cache;
}
