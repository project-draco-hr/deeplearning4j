{
  if (resetCounters && buildHuffmanTree)   throw new IllegalStateException("You can't reset counters and build Huffman tree at the same time!");
  if (cache == null)   cache=new InMemoryLookupCache(false);
  VocabularyHolder topHolder=new VocabularyHolder.Builder().externalCache(cache).minWordFrequency(0).build();
  for (  VocabSource source : sources) {
    LabelAwareIterator iterator=source.getIterator();
    iterator.reset();
    VocabularyHolder tempHolder=new VocabularyHolder.Builder().minWordFrequency(source.getMinWordFrequency()).build();
    while (iterator.hasNextDocument()) {
      LabelledDocument document=iterator.nextDocument();
      Tokenizer tokenizer=tokenizerFactory.create(document.getContent());
      if (fetchLabels) {
        VocabularyWord word=new VocabularyWord(document.getLabel());
        word.setSpecial(true);
        word.setCount(1);
        tempHolder.addWord(word);
      }
      List<String> tokens=tokenizer.getTokens();
      for (      String token : tokens) {
        if (stopWords != null && stopWords.contains(token))         continue;
        if (token == null || token.isEmpty())         continue;
        if (!tempHolder.containsWord(token)) {
          tempHolder.addWord(token);
        }
 else {
          tempHolder.incrementWordCounter(token);
        }
      }
    }
    log.info("Vocab size before truncation: " + tempHolder.numWords());
    tempHolder.truncateVocabulary();
    log.info("Vocab size after truncation: " + tempHolder.numWords());
    topHolder.consumeVocabulary(tempHolder);
  }
  if (resetCounters)   topHolder.resetWordCounters();
  if (buildHuffmanTree)   topHolder.updateHuffmanCodes();
  topHolder.transferBackToVocabCache(cache);
  return cache;
}
