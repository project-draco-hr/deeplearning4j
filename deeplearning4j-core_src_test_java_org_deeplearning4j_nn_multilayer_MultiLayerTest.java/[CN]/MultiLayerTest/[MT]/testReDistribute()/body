{
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.CONJUGATE_GRADIENT).constrainGradientToUnitNorm(true).iterations(5).learningRate(1e-3).list(4).layer(0,new RBM.Builder(RBM.HiddenUnit.RECTIFIED,RBM.VisibleUnit.GAUSSIAN).nIn(200).nOut(600).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1e-5)).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build()).layer(1,new RBM.Builder(RBM.HiddenUnit.RECTIFIED,RBM.VisibleUnit.GAUSSIAN).nIn(600).nOut(250).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1e-5)).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build()).layer(2,new RBM.Builder(RBM.HiddenUnit.RECTIFIED,RBM.VisibleUnit.GAUSSIAN).nIn(250).nOut(100).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1e-5)).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build()).layer(3,new org.deeplearning4j.nn.conf.layers.OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).nIn(100).nOut(50).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1e-5)).build()).build();
  MultiLayerNetwork network=new MultiLayerNetwork(conf);
  network.init();
  INDArray params=network.params();
  network.reDistributeParams();
  INDArray params2=network.params();
  assertEquals(params,params2);
}
