{
  int nIn=30;
  int nOut=25;
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.CONJUGATE_GRADIENT).iterations(5).learningRate(1e-3).list().layer(0,new RBM.Builder(RBM.HiddenUnit.RECTIFIED,RBM.VisibleUnit.GAUSSIAN).nIn(nIn).nOut(600).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1e-5)).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build()).layer(1,new RBM.Builder(RBM.HiddenUnit.RECTIFIED,RBM.VisibleUnit.GAUSSIAN).nIn(600).nOut(250).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1e-5)).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build()).layer(2,new RBM.Builder(RBM.HiddenUnit.RECTIFIED,RBM.VisibleUnit.GAUSSIAN).nIn(250).nOut(100).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1e-5)).lossFunction(LossFunctions.LossFunction.RMSE_XENT).build()).layer(3,new org.deeplearning4j.nn.conf.layers.OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).nIn(100).nOut(25).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1e-5)).build()).build();
  MultiLayerNetwork network=new MultiLayerNetwork(conf);
  network.init();
  INDArray input=Nd4j.rand(5,nIn);
  List<INDArray> activations=network.feedForward(input);
  assertEquals(5,activations.size());
  List<INDArray> activationsAll=network.feedForwardToLayer(3,input);
  assertEquals(activations,activationsAll);
  for (int i=3; i >= 0; i--) {
    List<INDArray> activationsPartial=network.feedForwardToLayer(i,input);
    assertEquals(i + 2,activationsPartial.size());
    for (int j=0; j <= i; j++) {
      INDArray exp=activationsAll.get(j);
      INDArray act=activationsPartial.get(j);
      assertEquals(exp,act);
    }
  }
}
