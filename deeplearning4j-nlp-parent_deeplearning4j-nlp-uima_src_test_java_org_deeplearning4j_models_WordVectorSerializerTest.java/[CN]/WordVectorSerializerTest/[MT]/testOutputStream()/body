{
  File file=File.createTempFile("tmp_ser","ssa");
  file.deleteOnExit();
  File inputFile=new ClassPathResource("/big/raw_sentences.txt").getFile();
  SentenceIterator iter=new BasicLineIterator(inputFile);
  TokenizerFactory t=new DefaultTokenizerFactory();
  t.setTokenPreProcessor(new CommonPreprocessor());
  InMemoryLookupCache cache=new InMemoryLookupCache(false);
  WeightLookupTable table=new InMemoryLookupTable.Builder().vectorLength(100).useAdaGrad(false).negative(5.0).cache(cache).lr(0.025f).build();
  Word2Vec vec=new Word2Vec.Builder().minWordFrequency(5).iterations(1).epochs(1).layerSize(100).lookupTable(table).stopWords(new ArrayList<String>()).useAdaGrad(false).negativeSample(5).vocabCache(cache).seed(42).windowSize(5).iterate(iter).tokenizerFactory(t).build();
  assertEquals(new ArrayList<String>(),vec.getStopWords());
  vec.fit();
  INDArray day1=vec.getWordVectorMatrix("day");
  WordVectorSerializer.writeWordVectors(vec,new FileOutputStream(file));
  WordVectors vec2=WordVectorSerializer.loadTxtVectors(file);
  INDArray day2=vec2.getWordVectorMatrix("day");
  assertEquals(day1,day2);
}
