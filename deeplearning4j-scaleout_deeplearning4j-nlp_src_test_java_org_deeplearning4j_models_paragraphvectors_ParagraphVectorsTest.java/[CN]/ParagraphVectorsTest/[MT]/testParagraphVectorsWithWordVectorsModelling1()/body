{
  ClassPathResource resource=new ClassPathResource("/big/raw_sentences.txt");
  File file=resource.getFile();
  SentenceIterator iter=new BasicLineIterator(file);
  InMemoryLookupCache cache=new InMemoryLookupCache(false);
  TokenizerFactory t=new DefaultTokenizerFactory();
  t.setTokenPreProcessor(new CommonPreprocessor());
  LabelsSource source=new LabelsSource("DOC_");
  ParagraphVectors vec=new ParagraphVectors.Builder().minWordFrequency(1).iterations(3).epochs(1).layerSize(100).learningRate(0.025).labelsGenerator(source).windowSize(5).iterate(iter).trainWordVectors(true).vocabCache(cache).tokenizerFactory(t).sampling(0).build();
  vec.fit();
  int cnt1=cache.wordFrequency("day");
  int cnt2=cache.wordFrequency("me");
  assertNotEquals(1,cnt1);
  assertNotEquals(1,cnt2);
  assertNotEquals(cnt1,cnt2);
  double similarityD=vec.similarity("day","night");
  log.info("day/night similarity: " + similarityD);
  double similarityW=vec.similarity("way","work");
  log.info("way/work similarity: " + similarityW);
  double similarityH=vec.similarity("house","world");
  log.info("house/world similarity: " + similarityH);
  double similarityC=vec.similarity("case","way");
  log.info("case/way similarity: " + similarityC);
  double similarity1=vec.similarity("DOC_9835","DOC_12492");
  log.info("9835/12492 similarity: " + similarity1);
  double similarity2=vec.similarity("DOC_3720","DOC_16392");
  log.info("3720/16392 similarity: " + similarity2);
  double similarity3=vec.similarity("DOC_6347","DOC_3720");
  log.info("6347/3720 similarity: " + similarity3);
  double similarityX=vec.similarity("DOC_3720","DOC_9852");
  log.info("3720/9852 similarity: " + similarityX);
  assertTrue(similarityX < 0.5d);
}
