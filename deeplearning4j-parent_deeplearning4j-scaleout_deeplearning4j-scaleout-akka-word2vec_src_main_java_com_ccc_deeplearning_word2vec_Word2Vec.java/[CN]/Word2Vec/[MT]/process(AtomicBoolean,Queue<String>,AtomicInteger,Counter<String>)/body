{
  Future<Void> f=Futures.future(new Callable<Void>(){
    @Override public Void call() throws Exception {
      while (!work.isEmpty()) {
        String words=work.poll();
        if (words == null)         return null;
        Tokenizer tokenizer=tokenizerFactory.create(new InputHomogenization(words).transform());
        Word2Vec.this.allWordsCount+=tokenizer.countTokens();
        int curr=count.incrementAndGet();
        if (curr % 10000 == 0)         log.info("Processed  sentence " + count + " current word count "+ allWordsCount+ " with sentence "+ words);
        words=null;
        while (tokenizer.hasMoreTokens()) {
          String token=tokenizer.nextToken();
          if (stopWords.contains(token))           token="STOP";
          rawVocab.incrementCount(token,1.0);
          if (rawVocab.getCount(token) >= minWordFrequency && !matchesAnyStopWord(token)) {
            if (!Word2Vec.this.vocab.containsKey(token)) {
              VocabWord word=new VocabWord(rawVocab.getCount(token),layerSize);
              word.setIndex(Word2Vec.this.vocab.size());
              Word2Vec.this.vocab.put(token,word);
              wordIndex.add(token);
            }
          }
          token=null;
        }
        tokenizer=null;
        numSentencesProcessed.incrementAndGet();
      }
      return null;
    }
  }
,trainingSystem.dispatcher());
  f.onComplete(new OnComplete<Void>(){
    @Override public void onComplete(    Throwable arg0,    Void arg1) throws Throwable {
      if (arg0 != null)       throw arg0;
      if (!sentenceIter.hasNext())       bool.getAndSet(true);
    }
  }
,trainingSystem.dispatcher());
}
