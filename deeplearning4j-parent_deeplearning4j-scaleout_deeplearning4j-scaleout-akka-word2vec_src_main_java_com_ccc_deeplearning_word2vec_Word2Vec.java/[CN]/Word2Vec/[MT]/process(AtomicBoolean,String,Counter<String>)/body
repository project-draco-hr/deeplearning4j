{
  Future<Void> f=Futures.future(new Callable<Void>(){
    @Override public Void call() throws Exception {
      if (words == null)       return null;
      Tokenizer tokenizer=tokenizerFactory.create(new InputHomogenization(words).transform());
      allWordsCount+=tokenizer.countTokens();
      if (allWordsCount % 100000 == 0)       log.info("New number of words " + allWordsCount);
      while (tokenizer.hasMoreTokens()) {
        String token=tokenizer.nextToken();
        if (stopWords.contains(token))         token="STOP";
        rawVocab.incrementCount(token,1.0);
        if (rawVocab.getCount(token) >= minWordFrequency && !matchesAnyStopWord(token)) {
          if (!vocab.containsKey(token)) {
            VocabWord word=new VocabWord(rawVocab.getCount(token),layerSize);
            word.setIndex(Word2Vec.this.vocab.size());
            vocab.put(token,word);
            wordIndex.add(token);
          }
        }
        token=null;
      }
      tokenizer=null;
      return null;
    }
  }
,trainingSystem.dispatcher());
  f.onComplete(new OnComplete<Void>(){
    @Override public void onComplete(    Throwable arg0,    Void arg1) throws Throwable {
      if (arg0 != null)       throw arg0;
      if (!sentenceIter.hasNext())       bool.getAndSet(true);
    }
  }
,trainingSystem.dispatcher());
  return f;
}
