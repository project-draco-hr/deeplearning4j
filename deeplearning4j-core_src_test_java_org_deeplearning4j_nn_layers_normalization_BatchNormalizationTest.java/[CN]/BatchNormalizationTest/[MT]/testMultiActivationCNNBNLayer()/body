{
  DataSetIterator iter=new MnistDataSetIterator(2,2);
  DataSet next=iter.next();
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.LINE_GRADIENT_DESCENT).iterations(2).seed(123).list().layer(0,new ConvolutionLayer.Builder().nIn(1).nOut(6).weightInit(WeightInit.XAVIER).activation("relu").build()).layer(1,new BatchNormalization.Builder().build()).layer(2,new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).weightInit(WeightInit.XAVIER).activation("softmax").nOut(10).build()).backprop(true).pretrain(false).cnnInputSize(28,28,1).build();
  MultiLayerNetwork network=new MultiLayerNetwork(conf);
  network.init();
  network.fit(next);
  MultiLayerConfiguration conf2=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.LINE_GRADIENT_DESCENT).iterations(2).seed(123).list().layer(0,new ConvolutionLayer.Builder().nIn(1).nOut(6).weightInit(WeightInit.XAVIER).activation("identity").build()).layer(1,new BatchNormalization.Builder().build()).layer(2,new ActivationLayer.Builder().activation("relu").build()).layer(3,new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).weightInit(WeightInit.XAVIER).activation("softmax").nOut(10).build()).backprop(true).pretrain(false).cnnInputSize(28,28,1).build();
  MultiLayerNetwork network2=new MultiLayerNetwork(conf2);
  network2.init();
  network2.fit(next);
  assertEquals(network.getLayer(0).getParam("W"),network2.getLayer(0).getParam("W"));
  assertEquals(network.getLayer(2).getParam("W"),network2.getLayer(3).getParam("W"));
  assertEquals(network.getLayer(0).getParam("b"),network2.getLayer(0).getParam("b"));
  assertEquals(network.getLayer(2).getParam("b"),network2.getLayer(3).getParam("b"));
}
