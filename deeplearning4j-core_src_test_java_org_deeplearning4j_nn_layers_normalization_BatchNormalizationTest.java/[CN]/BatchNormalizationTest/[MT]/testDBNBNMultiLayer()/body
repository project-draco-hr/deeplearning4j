{
  DataSetIterator iter=new MnistDataSetIterator(2,2);
  DataSet next=iter.next();
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).iterations(2).seed(123).list().layer(0,new DenseLayer.Builder().nIn(28 * 28 * 1).nOut(10).weightInit(WeightInit.XAVIER).activation("relu").build()).layer(1,new BatchNormalization.Builder().nOut(10).build()).layer(2,new ActivationLayer.Builder().activation("relu").build()).layer(3,new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).weightInit(WeightInit.XAVIER).activation("softmax").nIn(10).nOut(10).build()).backprop(true).pretrain(false).build();
  MultiLayerNetwork network=new MultiLayerNetwork(conf);
  network.init();
  network.setInput(next.getFeatureMatrix());
  INDArray activationsActual=network.preOutput(next.getFeatureMatrix());
  assertEquals(10,activationsActual.shape()[1],1e-2);
  network.fit(next);
  INDArray actualGammaParam=network.getLayer(1).getParam(BatchNormalizationParamInitializer.GAMMA);
  INDArray actualBetaParam=network.getLayer(1).getParam(BatchNormalizationParamInitializer.BETA);
  assertTrue(actualGammaParam != null);
  assertTrue(actualBetaParam != null);
}
