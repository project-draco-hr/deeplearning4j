{
  NeuralNetConfiguration ret=new NeuralNetConfiguration(sparsity,useAdaGrad,lr,k,corruptionLevel,numIterations,momentum,l2,useRegularization,momentumAfter,resetAdaGradIterations,dropOut,applySparsity,weightInit,optimizationAlgo,lossFunction,constrainGradientToUnitNorm,rng,seed,dist,nIn,nOut,activationFunction,visibleUnit,hiddenUnit,weightShape,filterSize,stride,featureMapSize,kernel,batchSize,numLineSearchIterations,maxNumLineSearchIterations,minimize,layer,convolutionType,poolingType,l1,customLossFunction);
  ret.useAdaGrad=this.useAdaGrad;
  ret.rmsDecay=rmsDecay;
  ret.stepFunction=stepFunction;
  ret.useDropConnect=useDropConnect;
  ret.rho=rho;
  ret.updater=updater;
  ret.channels=channels;
  if (layer != null) {
    Class<? extends Layer> layerClazz=layer.getClass();
    Field[] neuralNetConfFields=NeuralNetConfiguration.class.getDeclaredFields();
    Field[] layerFields=layerClazz.getDeclaredFields();
    for (    Field neuralNetField : neuralNetConfFields) {
      for (      Field layerField : layerFields) {
        if (neuralNetField.getName().equals(layerField.getName())) {
          try {
            Object valForConfig=neuralNetField.get(this);
            Object layerFieldValue=layerField.get(layer);
            if (layerFieldValue != null) {
              if (valForConfig.getClass().isAssignableFrom(layerFieldValue.getClass())) {
                neuralNetField.set(this,layerFieldValue);
              }
            }
          }
 catch (          Exception e) {
            throw new RuntimeException(e);
          }
        }
      }
    }
  }
  return ret;
}
