{
  if (adaGrad == null)   adaGrad=new AdaGrad(params.shape());
  if (lastStep == null)   lastStep=Nd4j.ones((params.shape()));
  double momentum=conf.getLayer().getMomentum();
  if (conf.getLayer().getMomentumAfter() != null && !conf.getLayer().getMomentumAfter().isEmpty()) {
    int key=conf.getLayer().getMomentumAfter().keySet().iterator().next();
    if (iteration >= key) {
      momentum=conf.getLayer().getMomentumAfter().get(key);
    }
  }
  if (conf.getLayer().getRmsDecay() > 0) {
    lastStep.assign(lastStep.mul(conf.getLayer().getRmsDecay()).addi(Transforms.pow(gradient,2).muli((1 - conf.getLayer().getRmsDecay()))));
    gradient=gradient.mul(conf.getLayer().getLearningRate()).negi().divi(Transforms.sqrt(lastStep.add(Nd4j.EPS_THRESHOLD)));
  }
  gradient=adaGrad.getGradient(gradient,0);
  if (momentum > 0) {
    gradient=lastStep.mul(momentum).subi(gradient);
    lastStep.assign(gradient);
  }
  if (conf.isUseRegularization() && conf.getLayer().getL2() > 0 && !(gradient.equals(DefaultParamInitializer.BIAS_KEY)))   gradient.subi(params.mul(conf.getLayer().getL2()));
 else   if (conf.isUseRegularization() && conf.getLayer().getL1() < 0 && !(gradient.equals(DefaultParamInitializer.BIAS_KEY)))   gradient.subi(Transforms.sign(params).muli(conf.getLayer().getL1()));
  if (conf.isConstrainGradientToUnitNorm())   gradient.divi(gradient.norm2(Integer.MAX_VALUE));
  gradient.divi(batchSize);
}
