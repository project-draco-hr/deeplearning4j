{
  system=ActorSystem.create(systemName);
  ActorRefUtils.addShutDownForSystem(system);
  mediator=DistributedPubSubExtension.get(system).mediator();
  epochs=conf.getPretrainEpochs();
  if (type.equals("master")) {
    if (iter == null)     throw new IllegalStateException("Unable to initialize no dataset to train");
    log.info("Starting master");
    try {
      masterAddress=startBackend(null,"master",conf,iter,new HazelCastStateTracker());
      Thread.sleep(60000);
    }
 catch (    Exception e1) {
      Thread.currentThread().interrupt();
      throw new RuntimeException(e1);
    }
    log.info("Starting model saver");
    system.actorOf(Props.create(ModelSavingActor.class,"model-saver"));
    Cluster.get(system).join(masterAddress);
    conf.setMasterUrl(getMasterAddress().toString());
    conf.setMasterAbsPath(ActorRefUtils.absPath(masterActor,system));
    ActorRefUtils.registerConfWithZooKeeper(conf,system);
    system.scheduler().schedule(Duration.create(1,TimeUnit.MINUTES),Duration.create(1,TimeUnit.MINUTES),new Runnable(){
      @Override public void run(){
        log.info("Current cluster members " + Cluster.get(system).readView().members());
      }
    }
,system.dispatcher());
    log.info("Setup master with epochs " + epochs);
  }
 else {
    Conf c=conf.copy();
    Cluster cluster=Cluster.get(system);
    cluster.join(masterAddress);
    startWorker(masterAddress,c);
    system.scheduler().schedule(Duration.create(1,TimeUnit.MINUTES),Duration.create(1,TimeUnit.MINUTES),new Runnable(){
      @Override public void run(){
        log.info("Current cluster members " + Cluster.get(system).readView().members());
      }
    }
,system.dispatcher());
    log.info("Setup worker nodes");
  }
}
