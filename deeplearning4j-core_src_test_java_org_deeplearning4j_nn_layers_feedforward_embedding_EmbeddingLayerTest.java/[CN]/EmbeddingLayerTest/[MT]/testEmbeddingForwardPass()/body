{
  int nClassesIn=10;
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().activation("tanh").list(2).layer(0,new EmbeddingLayer.Builder().nIn(nClassesIn).nOut(5).build()).layer(1,new OutputLayer.Builder().nIn(5).nOut(4).build()).pretrain(false).backprop(true).build();
  MultiLayerConfiguration conf2=new NeuralNetConfiguration.Builder().activation("tanh").list(2).layer(0,new DenseLayer.Builder().nIn(nClassesIn).nOut(5).build()).layer(1,new OutputLayer.Builder().nIn(5).nOut(4).build()).pretrain(false).backprop(true).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  MultiLayerNetwork net2=new MultiLayerNetwork(conf2);
  net.init();
  net2.init();
  net2.setParams(net.params().dup());
  int batchSize=3;
  INDArray inEmbedding=Nd4j.create(batchSize,1);
  INDArray inOneHot=Nd4j.create(batchSize,nClassesIn);
  Random r=new Random(12345);
  for (int i=0; i < batchSize; i++) {
    int classIdx=r.nextInt(nClassesIn);
    inEmbedding.putScalar(i,classIdx);
    inOneHot.putScalar(new int[]{i,classIdx},1.0);
  }
  List<INDArray> activationsEmbedding=net.feedForward(inEmbedding,false);
  List<INDArray> activationsDense=net2.feedForward(inOneHot,false);
  for (int i=1; i < 3; i++) {
    INDArray actE=activationsEmbedding.get(i);
    INDArray actD=activationsDense.get(i);
    assertEquals(actE,actD);
  }
}
