{
  JavaSparkContext sc=getContext();
  JavaRDD<String> corpusRDD=getCorpusRDD(sc);
  Broadcast<Map<String,Object>> broadcastTokenizerVarMap=sc.broadcast(word2vec.getTokenizerVarMap());
  TextPipeline pipeline=new TextPipeline(corpusRDD,broadcastTokenizerVarMap);
  pipeline.buildVocabCache();
  pipeline.buildVocabWordListRDD();
  JavaRDD<AtomicLong> sentenceCountRDD=pipeline.getSentenceCountRDD();
  JavaRDD<List<VocabWord>> vocabWordListRDD=pipeline.getVocabWordListRDD();
  CountCumSum countCumSum=new CountCumSum(sentenceCountRDD);
  JavaRDD<Long> sentenceCountCumSumRDD=countCumSum.buildCumSum();
  JavaPairRDD<List<VocabWord>,Long> vocabWordListSentenceCumSumRDD=vocabWordListRDD.zip(sentenceCountCumSumRDD);
  List<Tuple2<List<VocabWord>,Long>> lst=vocabWordListSentenceCumSumRDD.collect();
  List<VocabWord> vocabWordsList1=lst.get(0)._1();
  Long cumSumSize1=lst.get(0)._2();
  assertEquals(3,vocabWordsList1.size());
  assertEquals(vocabWordsList1.get(0).getWord(),"strange");
  assertEquals(vocabWordsList1.get(1).getWord(),"strange");
  assertEquals(vocabWordsList1.get(2).getWord(),"world");
  assertEquals(cumSumSize1,6L,0);
  List<VocabWord> vocabWordsList2=lst.get(1)._1();
  Long cumSumSize2=lst.get(1)._2();
  assertEquals(2,vocabWordsList2.size());
  assertEquals(vocabWordsList2.get(0).getWord(),"flowers");
  assertEquals(vocabWordsList2.get(1).getWord(),"red");
  assertEquals(cumSumSize2,9L,0);
  sc.stop();
}
