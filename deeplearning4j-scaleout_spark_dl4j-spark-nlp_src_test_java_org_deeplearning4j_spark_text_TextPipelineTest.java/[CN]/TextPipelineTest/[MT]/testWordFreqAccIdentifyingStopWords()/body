{
  JavaSparkContext sc=getContext();
  JavaRDD<String> corpusRDD=getCorpusRDD(sc);
  Broadcast<Map<String,Object>> broadcastTokenizerVarMap=sc.broadcast(word2vec.getTokenizerVarMap());
  TextPipeline pipeline=new TextPipeline(corpusRDD,broadcastTokenizerVarMap);
  JavaRDD<List<String>> tokenizedRDD=pipeline.tokenize();
  pipeline.updateAndReturnAccumulatorVal(tokenizedRDD);
  Counter<String> wordFreqCounter=pipeline.getWordFreqAcc().value();
  assertEquals(wordFreqCounter.getCount("is"),0,0);
  assertEquals(wordFreqCounter.getCount("this"),0,0);
  assertEquals(wordFreqCounter.getCount("are"),0,0);
  assertEquals(wordFreqCounter.getCount("a"),0,0);
  assertEquals(wordFreqCounter.getCount("STOP"),4,0);
  assertEquals(wordFreqCounter.getCount("strange"),2,0);
  assertEquals(wordFreqCounter.getCount("flowers"),1,0);
  assertEquals(wordFreqCounter.getCount("world"),1,0);
  assertEquals(wordFreqCounter.getCount("red"),1,0);
  sc.stop();
}
