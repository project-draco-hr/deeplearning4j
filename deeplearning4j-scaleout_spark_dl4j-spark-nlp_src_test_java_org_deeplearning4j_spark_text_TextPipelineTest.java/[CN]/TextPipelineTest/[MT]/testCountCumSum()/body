{
  JavaSparkContext sc=getContext();
  JavaRDD<String> corpusRDD=getCorpusRDD(sc);
  Broadcast<Map<String,Object>> broadcastTokenizerVarMap=sc.broadcast(word2vec.getTokenizerVarMap());
  TextPipeline pipeline=new TextPipeline(corpusRDD,broadcastTokenizerVarMap);
  pipeline.buildVocabCache();
  pipeline.buildVocabWordListRDD();
  JavaRDD<AtomicLong> sentenceCountRDD=pipeline.getSentenceCountRDD();
  CountCumSum countCumSum=new CountCumSum(sentenceCountRDD);
  JavaRDD<Long> sentenceCountCumSumRDD=countCumSum.buildCumSum();
  List<Long> sentenceCountCumSumList=sentenceCountCumSumRDD.collect();
  assertTrue(sentenceCountCumSumList.get(0) == 6L);
  assertTrue(sentenceCountCumSumList.get(1) == 9L);
  sc.stop();
}
