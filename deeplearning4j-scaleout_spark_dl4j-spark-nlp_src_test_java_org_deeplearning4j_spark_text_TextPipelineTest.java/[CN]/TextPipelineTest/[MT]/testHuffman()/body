{
  JavaSparkContext sc=new JavaSparkContext(conf);
  JavaRDD<String> corpusRDD=getCorpusRDD(sc);
  TextPipeline pipeline=new TextPipeline(corpusRDD,word2vec.getTokenizerVarMap());
  pipeline.buildVocabCache();
  VocabCache vocabCache=pipeline.getVocabCache();
  Huffman huffman=new Huffman(vocabCache.vocabWords());
  huffman.build();
  Collection<VocabWord> vocabWords=vocabCache.vocabWords();
  System.out.println("Huffman Test:");
  for (  VocabWord vocabWord : vocabWords) {
    System.out.println(vocabWord.getCodes());
    System.out.println(vocabWord.getPoints());
  }
  sc.stop();
}
