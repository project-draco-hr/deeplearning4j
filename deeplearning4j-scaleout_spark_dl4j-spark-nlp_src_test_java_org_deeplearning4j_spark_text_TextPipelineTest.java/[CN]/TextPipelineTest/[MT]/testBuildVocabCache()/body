{
  JavaSparkContext sc=getContext();
  JavaRDD<String> corpusRDD=getCorpusRDD(sc);
  Broadcast<Map<String,Object>> broadcastTokenizerVarMap=sc.broadcast(word2vec.getTokenizerVarMap());
  TextPipeline pipeline=new TextPipeline(corpusRDD,broadcastTokenizerVarMap);
  pipeline.buildVocabCache();
  VocabCache<VocabWord> vocabCache=pipeline.getVocabCache();
  assertTrue(vocabCache != null);
  assertEquals(4,vocabCache.numWords());
  VocabWord redVocab=vocabCache.tokenFor("red");
  VocabWord flowerVocab=vocabCache.tokenFor("flowers");
  VocabWord worldVocab=vocabCache.tokenFor("world");
  VocabWord strangeVocab=vocabCache.tokenFor("strange");
  log.info("Red word: " + redVocab);
  log.info("Flower word: " + flowerVocab);
  log.info("World word: " + worldVocab);
  log.info("Strange word: " + strangeVocab);
  assertEquals(redVocab.getWord(),"red");
  assertEquals(redVocab.getElementFrequency(),1,0);
  assertEquals(flowerVocab.getWord(),"flowers");
  assertEquals(flowerVocab.getElementFrequency(),1,0);
  assertEquals(worldVocab.getWord(),"world");
  assertEquals(worldVocab.getElementFrequency(),1,0);
  assertEquals(strangeVocab.getWord(),"strange");
  assertEquals(strangeVocab.getElementFrequency(),2,0);
  sc.stop();
}
