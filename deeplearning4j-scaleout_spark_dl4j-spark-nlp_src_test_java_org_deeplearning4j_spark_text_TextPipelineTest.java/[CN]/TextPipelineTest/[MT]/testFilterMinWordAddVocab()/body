{
  JavaSparkContext sc=new JavaSparkContext(getConfClone());
  JavaRDD<String> corpusRDD=getCorpusRDD(sc);
  TextPipeline pipeline=new TextPipeline(corpusRDD);
  JavaRDD<List<String>> tokenizedRDD=pipeline.tokenize();
  pipeline.updateAndReturnAccumulatorVal(tokenizedRDD).collect();
  Counter<String> wordFreqCounter=pipeline.getWordFreqAcc().value();
  pipeline.filterMinWordAddVocab(wordFreqCounter);
  VocabCache vocabCache=pipeline.getVocabCache();
  assertTrue(vocabCache != null);
  VocabWord redVocab=vocabCache.tokenFor("red");
  VocabWord flowerVocab=vocabCache.tokenFor("flowers");
  VocabWord worldVocab=vocabCache.tokenFor("world");
  VocabWord strangeVocab=vocabCache.tokenFor("strange");
  assertEquals(redVocab.getWord(),"red");
  assertEquals(redVocab.getIndex(),0);
  assertEquals(redVocab.getWordFrequency(),1,0);
  assertEquals(flowerVocab.getWord(),"flowers");
  assertEquals(flowerVocab.getIndex(),1);
  assertEquals(flowerVocab.getWordFrequency(),1,0);
  assertEquals(worldVocab.getWord(),"world");
  assertEquals(worldVocab.getIndex(),2);
  assertEquals(worldVocab.getWordFrequency(),1,0);
  assertEquals(strangeVocab.getWord(),"strange");
  assertEquals(strangeVocab.getIndex(),3);
  assertEquals(strangeVocab.getWordFrequency(),2,0);
  sc.stop();
}
