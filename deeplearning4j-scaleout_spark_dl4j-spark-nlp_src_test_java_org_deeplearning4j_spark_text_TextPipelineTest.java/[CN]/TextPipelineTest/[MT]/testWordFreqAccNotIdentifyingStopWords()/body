{
  JavaSparkContext sc=getContext();
  JavaRDD<String> corpusRDD=getCorpusRDD(sc);
  Broadcast<Map<String,Object>> broadcastTokenizerVarMap=sc.broadcast(word2vecNoStop.getTokenizerVarMap());
  TextPipeline pipeline=new TextPipeline(corpusRDD,broadcastTokenizerVarMap);
  JavaRDD<List<String>> tokenizedRDD=pipeline.tokenize();
  pipeline.updateAndReturnAccumulatorVal(tokenizedRDD);
  Counter<String> wordFreqCounter=pipeline.getWordFreqAcc().value();
  assertEquals(wordFreqCounter.getCount("is"),1,0);
  assertEquals(wordFreqCounter.getCount("this"),1,0);
  assertEquals(wordFreqCounter.getCount("are"),1,0);
  assertEquals(wordFreqCounter.getCount("a"),1,0);
  assertEquals(wordFreqCounter.getCount("strange"),2,0);
  assertEquals(wordFreqCounter.getCount("flowers"),1,0);
  assertEquals(wordFreqCounter.getCount("world"),1,0);
  assertEquals(wordFreqCounter.getCount("red"),1,0);
  sc.stop();
}
