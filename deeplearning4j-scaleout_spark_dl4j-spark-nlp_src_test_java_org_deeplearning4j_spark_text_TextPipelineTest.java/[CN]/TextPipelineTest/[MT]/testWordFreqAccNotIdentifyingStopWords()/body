{
  SparkConf confCopy=getConfClone().set(REMOVE_STOPWORDS,String.valueOf(false));
  JavaSparkContext sc=new JavaSparkContext(confCopy);
  JavaRDD<String> corpusRDD=getCorpusRDD(sc);
  TextPipeline pipeline=new TextPipeline(corpusRDD);
  JavaRDD<List<String>> tokenizedRDD=pipeline.tokenize();
  pipeline.updateAndReturnAccumulatorVal(tokenizedRDD);
  Counter<String> wordFreqCounter=pipeline.getWordFreqAcc().value();
  assertEquals(wordFreqCounter.getCount("is"),1,0);
  assertEquals(wordFreqCounter.getCount("this"),1,0);
  assertEquals(wordFreqCounter.getCount("are"),1,0);
  assertEquals(wordFreqCounter.getCount("a"),1,0);
  assertEquals(wordFreqCounter.getCount("strange"),2,0);
  assertEquals(wordFreqCounter.getCount("flowers"),1,0);
  assertEquals(wordFreqCounter.getCount("world"),1,0);
  assertEquals(wordFreqCounter.getCount("red"),1,0);
  sc.stop();
}
