{
  if (args.length < 2) {
    System.err.println("Usage: JavaDirectKafkaWordCount <brokers> <topics>\n" + "  <brokers> is a list of one or more Kafka brokers\n" + "  <topics> is a list of one or more kafka topics to consume from\n\n");
    System.exit(1);
  }
  String brokers=args[0];
  String topics=args[1];
  SparkConf sparkConf=new SparkConf().setAppName("JavaDirectKafkaWordCount");
  JavaStreamingContext jssc=new JavaStreamingContext(sparkConf,Durations.seconds(2));
  Set<String> topicsSet=new HashSet<>(Arrays.asList(topics.split(",")));
  Map<String,String> kafkaParams=new HashMap<>();
  kafkaParams.put("metadata.broker.list",brokers);
  JavaPairInputDStream<String,String> messages=KafkaUtils.createDirectStream(jssc,String.class,String.class,StringDecoder.class,StringDecoder.class,kafkaParams,topicsSet);
  JavaDStream<String> lines=messages.map(new Function<Tuple2<String,String>,String>(){
    @Override public String call(    Tuple2<String,String> tuple2){
      return tuple2._2();
    }
  }
);
  JavaDStream<String> words=lines.flatMap(new FlatMapFunction<String,String>(){
    @Override public Iterable<String> call(    String x){
      return Arrays.asList(SPACE.split(x));
    }
  }
);
  JavaPairDStream<String,Integer> wordCounts=words.mapToPair(new PairFunction<String,String,Integer>(){
    @Override public Tuple2<String,Integer> call(    String s){
      return new Tuple2<>(s,1);
    }
  }
).reduceByKey(new Function2<Integer,Integer,Integer>(){
    @Override public Integer call(    Integer i1,    Integer i2){
      return i1 + i2;
    }
  }
);
  wordCounts.print();
  jssc.start();
  jssc.awaitTermination();
}
