{
  JavaSparkContext sc=new JavaSparkContext(corpus.context());
  Broadcast<List<String>> broadcast=sc.broadcast(stopWords);
  return corpus.map(new TokenizerFunction()).map(new VocabCacheFunction(minWordFrequency,broadcast)).cache().collect().get(0);
}
