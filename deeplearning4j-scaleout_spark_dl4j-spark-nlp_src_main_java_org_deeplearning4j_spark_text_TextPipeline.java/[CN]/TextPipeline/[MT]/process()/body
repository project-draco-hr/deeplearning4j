{
  JavaSparkContext sc=new JavaSparkContext(corpus.context());
  Broadcast<List<String>> broadcast=sc.broadcast(stopWords);
  return corpus.map(new TokenizerFunction(DefaultTokenizerFactory.class.getName())).map(new VocabCacheFunction(minWordFrequency,new InMemoryLookupCache(),broadcast)).reduce(new ReduceVocabFunction());
}
