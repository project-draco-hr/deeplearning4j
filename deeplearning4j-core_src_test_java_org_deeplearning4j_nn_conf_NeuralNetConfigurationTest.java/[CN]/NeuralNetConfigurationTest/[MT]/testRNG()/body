{
  RBM layer=new RBM.Builder().nIn(trainingSet.numInputs()).nOut(trainingSet.numOutcomes()).weightInit(WeightInit.UNIFORM).visibleUnit(RBM.VisibleUnit.GAUSSIAN).hiddenUnit(RBM.HiddenUnit.RECTIFIED).activation("tanh").lossFunction(LossFunctions.LossFunction.RMSE_XENT).build();
  NeuralNetConfiguration conf=new NeuralNetConfiguration.Builder().seed(123).iterations(3).optimizationAlgo(OptimizationAlgorithm.CONJUGATE_GRADIENT).layer(layer).build();
  int numParams=LayerFactories.getFactory(conf).initializer().numParams(conf,true);
  INDArray params=Nd4j.create(1,numParams);
  Layer model=LayerFactories.getFactory(conf).create(conf,null,0,params,true);
  INDArray modelWeights=model.getParam(DefaultParamInitializer.WEIGHT_KEY);
  RBM layer2=new RBM.Builder().nIn(trainingSet.numInputs()).nOut(trainingSet.numOutcomes()).weightInit(WeightInit.UNIFORM).visibleUnit(RBM.VisibleUnit.GAUSSIAN).hiddenUnit(RBM.HiddenUnit.RECTIFIED).activation("tanh").lossFunction(LossFunctions.LossFunction.RMSE_XENT).build();
  NeuralNetConfiguration conf2=new NeuralNetConfiguration.Builder().seed(123).iterations(3).optimizationAlgo(OptimizationAlgorithm.CONJUGATE_GRADIENT).layer(layer2).build();
  int numParams2=LayerFactories.getFactory(conf2).initializer().numParams(conf,true);
  INDArray params2=Nd4j.create(1,numParams);
  Layer model2=LayerFactories.getFactory(conf2).create(conf2,null,0,params2,true);
  INDArray modelWeights2=model2.getParam(DefaultParamInitializer.WEIGHT_KEY);
  assertEquals(modelWeights,modelWeights2);
}
