{
  TokenizerFactory t=new DefaultTokenizerFactory();
  t.setTokenPreProcessor(new CommonPreprocessor());
  AbstractCache<VocabWord> cacheSource=new AbstractCache.Builder<VocabWord>().build();
  ClassPathResource resource=new ClassPathResource("big/raw_sentences.txt");
  BasicLineIterator underlyingIterator=new BasicLineIterator(resource.getFile());
  SentenceTransformer transformer=new SentenceTransformer.Builder().iterator(underlyingIterator).tokenizerFactory(t).build();
  AbstractSequenceIterator<VocabWord> sequenceIterator=new AbstractSequenceIterator.Builder<VocabWord>(transformer).build();
  VocabConstructor<VocabWord> vocabConstructor=new VocabConstructor.Builder<VocabWord>().addSource(sequenceIterator,1).setTargetVocabCache(cacheSource).build();
  vocabConstructor.buildJointVocabulary(false,true);
  assertEquals(244,cacheSource.numWords());
  InMemoryLookupTable<VocabWord> mem1=(InMemoryLookupTable<VocabWord>)new InMemoryLookupTable.Builder<VocabWord>().vectorLength(100).cache(cacheSource).seed(17).build();
  mem1.resetWeights(true);
  InMemoryLookupTable<VocabWord> mem2=(InMemoryLookupTable<VocabWord>)new InMemoryLookupTable.Builder<VocabWord>().vectorLength(100).cache(cacheSource).seed(15).build();
  mem2.resetWeights(true);
  assertNotEquals(mem1.vector("day"),mem2.vector("day"));
  mem2.consume(mem1);
  assertEquals(mem1.vector("day"),mem2.vector("day"));
}
