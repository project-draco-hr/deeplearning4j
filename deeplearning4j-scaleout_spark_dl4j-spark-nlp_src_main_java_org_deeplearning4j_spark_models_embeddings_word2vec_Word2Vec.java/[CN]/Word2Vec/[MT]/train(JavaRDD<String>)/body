{
  log.info("Start training ...");
  final JavaSparkContext sc=new JavaSparkContext(corpusRDD.context());
  final JavaRDD<AtomicLong> sentenceWordsCountRDD;
  final JavaRDD<List<VocabWord>> vocabWordListRDD;
  final Long totalWordCount;
  final JavaPairRDD<List<VocabWord>,Long> vocabWordListSentenceCumSumRDD;
  final VocabCache vocabCache;
  final Broadcast<VocabCache> vocabCacheBroadcast;
  final JavaRDD<Long> sentenceCumSumCountRDD;
  log.info("Tokenization and building VocabCache ...");
  TextPipeline pipeline=new TextPipeline(corpusRDD,getTokenizerVarMap());
  pipeline.buildVocabCache();
  pipeline.buildVocabWordListRDD();
  totalWordCount=pipeline.getTotalWordCount();
  sentenceWordsCountRDD=pipeline.getSentenceCountRDD();
  vocabWordListRDD=pipeline.getVocabWordListRDD();
  vocabCache=pipeline.getVocabCache();
  vocabCacheBroadcast=pipeline.getBroadCastVocabCache();
  log.info("Building Huffman Tree ...");
  Huffman huffman=new Huffman(vocabCache.vocabWords());
  huffman.build();
  log.info("Calculating cumulative sum of sentence counts ...");
  sentenceCumSumCountRDD=new CountCumSum(sentenceWordsCountRDD).buildCumSum();
  log.info("Mapping to RDD(vocabWordList, cumulative sentence count) ...");
  vocabWordListSentenceCumSumRDD=vocabWordListRDD.zip(sentenceCumSumCountRDD).setName("vocabWordListSentenceCumSumRDD").cache();
  log.info("Broadcasting word2vec variable map to workers ...");
  Broadcast<Map<String,Object>> word2vecVarMapBroadcast=sc.broadcast(getWord2vecVarMap());
  return new Pair<VocabCache,WeightLookupTable>(vocabCacheBroadcast.getValue(),lookupTable);
}
