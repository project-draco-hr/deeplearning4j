{
  LogisticRegressionOptimizer opt=new LogisticRegressionOptimizer(this,learningRate);
  adaGrad.setMasterStepSize(learningRate);
  biasAdaGrad.setMasterStepSize(learningRate);
  if (optimizationAlgorithm == OptimizationAlgorithm.CONJUGATE_GRADIENT) {
    VectorizedNonZeroStoppingConjugateGradient g=new VectorizedNonZeroStoppingConjugateGradient(opt);
    g.setTolerance(1e-5);
    g.setMaxIterations(numEpochs);
    g.optimize(numEpochs);
  }
 else {
    VectorizedDeepLearningGradientAscent g=new VectorizedDeepLearningGradientAscent(opt);
    g.setTolerance(1e-5);
    g.optimize(numEpochs);
  }
}
