{
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).learningRate(0.01).regularization(true).list().layer(0,new org.deeplearning4j.nn.conf.layers.ConvolutionLayer.Builder(4,4).nIn(1).nOut(10).padding(2,2).stride(2,2).weightInit(WeightInit.RELU).activation("relu").build()).layer(1,new org.deeplearning4j.nn.conf.layers.DenseLayer.Builder().activation("relu").nOut(200).build()).layer(2,new OutputLayer.Builder(LossFunctions.LossFunction.RMSE_XENT).nIn(200).nOut(5).weightInit(WeightInit.RELU).activation("softmax").updater(Updater.SGD).build()).cnnInputSize(28,28,1).backprop(true).pretrain(false).build();
  assertNotNull(conf.getInputPreProcess(0));
  assertNotNull(conf.getInputPreProcess(1));
  assertTrue(conf.getInputPreProcess(0) instanceof FeedForwardToCnnPreProcessor);
  assertTrue(conf.getInputPreProcess(1) instanceof CnnToFeedForwardPreProcessor);
  FeedForwardToCnnPreProcessor ffcnn=(FeedForwardToCnnPreProcessor)conf.getInputPreProcess(0);
  CnnToFeedForwardPreProcessor cnnff=(CnnToFeedForwardPreProcessor)conf.getInputPreProcess(1);
  assertEquals(28,ffcnn.getInputHeight());
  assertEquals(28,ffcnn.getInputWidth());
  assertEquals(1,ffcnn.getNumChannels());
  assertEquals(15,cnnff.getInputHeight());
  assertEquals(15,cnnff.getInputWidth());
  assertEquals(10,cnnff.getNumChannels());
  assertEquals(15 * 15 * 10,((FeedForwardLayer)conf.getConf(1).getLayer()).getNIn());
}
