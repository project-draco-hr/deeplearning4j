{
  boolean loaded=buildVocab();
  if (!loaded && saveVocab)   cache.saveVocab();
  if (stopWords == null)   readStopWords();
  log.info("Training word2vec multithreaded");
  if (sentenceIter != null)   sentenceIter.reset();
  if (docIter != null)   docIter.reset();
  final Collection<Integer> docs=vectorizer.index().allDocs();
  int tries=0;
  while (docs.isEmpty()) {
    if (tries >= 3)     throw new IllegalStateException("Unable to train, no documents found");
 else {
      log.warn("No documents found...waiting 10 seconds on try " + tries);
      try {
        Thread.sleep(10000);
      }
 catch (      InterruptedException e) {
        Thread.currentThread().interrupt();
      }
      tries++;
    }
  }
  final AtomicInteger numSentencesProcessed=new AtomicInteger(0);
  totalWords=vectorizer.numWordsEncountered();
  totalWords*=numIterations;
  log.info("Processing sentences...");
  List<Thread> work=new ArrayList<>();
  for (int i=0; i < Runtime.getRuntime().availableProcessors(); i++) {
    Thread t=new Thread(new Runnable(){
      @Override public void run(){
        final AtomicLong nextRandom=new AtomicLong(5);
        while (true) {
          List<VocabWord> sentence=jobQueue.poll();
          if (sentence != null && sentence.isEmpty())           break;
          if (sentence == null)           continue;
          trainSentence(sentence,numSentencesProcessed,nextRandom);
        }
      }
    }
);
    t.setDaemon(true);
    t.start();
    work.add(t);
  }
  final List<VocabWord> batch=new ArrayList<>();
  final AtomicLong nextRandom=new AtomicLong(5);
  final File miniBatchDir=new File(".minibatches");
  FileUtils.deleteDirectory(miniBatchDir);
  miniBatchDir.mkdirs();
  final AtomicInteger doc=new AtomicInteger(0);
  final int numDocs=vectorizer.index().numDocuments();
  vectorizer.index().eachDoc(new Function<List<VocabWord>,Void>(){
    @Nullable @Override public Void apply(    @Nullable List<VocabWord> input){
      addWords(input,nextRandom,batch);
      if (batch.size() >= batchSize) {
        SerializationUtils.saveObject(batch,new File(miniBatchDir,String.valueOf(doc)));
        doc.incrementAndGet();
        if (doc.get() % 10000 == 0)         log.info("Doc " + doc.get() + " done so far out of "+ numDocs);
        batch.clear();
      }
      return null;
    }
  }
);
  Iterator<File> miniBatches=FileUtils.iterateFiles(miniBatchDir,null,false);
  while (miniBatches.hasNext()) {
    List<VocabWord> miniBatch=SerializationUtils.readObject(miniBatches.next());
    try {
      while (!jobQueue.offerLast(miniBatch,100,TimeUnit.MILLISECONDS)) {
        try {
          Thread.sleep(100);
        }
 catch (        Exception e) {
          Thread.currentThread().interrupt();
        }
      }
    }
 catch (    Exception e) {
      Thread.currentThread().interrupt();
    }
  }
  if (!jobQueue.isEmpty()) {
    jobQueue.add(new ArrayList<>(batch));
    batch.clear();
  }
  for (int i=0; i < work.size(); i++)   jobQueue.add(new ArrayList<VocabWord>());
  for (  Thread t : work)   try {
    t.join();
  }
 catch (  InterruptedException e) {
    Thread.currentThread().interrupt();
  }
  for (int i=0; i < numIterations; i++) {
    log.info("Training on " + docs.size());
  }
}
