{
  readStopWords();
  if (trainingSystem == null)   trainingSystem=ActorSystem.create();
  final AtomicLong semaphore=new AtomicLong(System.currentTimeMillis());
  final AtomicInteger queued=new AtomicInteger(0);
  final ActorRef vocabActor=trainingSystem.actorOf(new RoundRobinPool(Runtime.getRuntime().availableProcessors()).props(Props.create(VocabActor.class,tokenizerFactory,cache,layerSize,stopWords,semaphore,minWordFrequency)));
  final AtomicInteger latch=new AtomicInteger(0);
  while (docIter != null && docIter.hasNext()) {
    InputStream is=docIter.nextDocument();
    Tokenizer t=tokenizerFactory.create(is);
    while (t.hasMoreTokens()) {
      String token=t.nextToken();
      if (stopWords.contains(token))       token="STOP";
      cache.incrementWordCount(token);
      if (!Util.matchesAnyStopWord(stopWords,token)) {
        if (cache.containsWord(token) && cache.wordFrequency(token) >= minWordFrequency) {
          VocabWord word=new VocabWord(cache.wordFrequency(token),token);
          int idx=cache.numWords();
          word.setIndex(idx);
          cache.putVocabWord(token,word);
          cache.addWordToIndex(idx,token);
        }
      }
    }
    IOUtils.closeQuietly(is);
  }
  while (getSentenceIter() != null && getSentenceIter().hasNext()) {
    String sentence=getSentenceIter().nextSentence();
    if (sentence == null)     break;
    vocabActor.tell(new VocabWork(latch,sentence),vocabActor);
    queued.incrementAndGet();
    if (queued.get() % 10000 == 0)     log.info("Sent " + queued);
  }
  try {
    Thread.sleep(10000);
  }
 catch (  InterruptedException e) {
    Thread.currentThread().interrupt();
  }
  while (latch.get() > 0) {
    log.info("Building vocab...");
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException e) {
      Thread.currentThread().interrupt();
    }
  }
  setup();
}
