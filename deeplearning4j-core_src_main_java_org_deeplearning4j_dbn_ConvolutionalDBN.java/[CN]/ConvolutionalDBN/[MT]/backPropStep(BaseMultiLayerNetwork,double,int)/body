{
  List<Pair<DoubleMatrix,DoubleMatrix>> deltas=new ArrayList<>();
  computeDeltas(deltas);
  for (int l=1; l < getnLayers(); l++) {
    ConvolutionalRBM r=(ConvolutionalRBM)getLayers()[l];
    ConvolutionalRBM prevR=(ConvolutionalRBM)getLayers()[l - 1];
    FourDTensor wGradient=(FourDTensor)deltas.get(l).getFirst();
    DoubleMatrix biasGradient=deltas.get(l).getSecond();
    FourDTensorAdaGrad wAdaGrad=(FourDTensorAdaGrad)r.getAdaGrad();
    DoubleMatrix biasLearningRates=null;
    if (useAdaGrad)     biasLearningRates=layers[l].gethBiasAdaGrad().getLearningRates(biasGradient);
    for (int m=0; m < r.getNumFilters()[0]; m++) {
      if (useAdaGrad)       biasGradient.put(m,biasLearningRates.get(m) * r.gethBias().get(m));
 else       biasGradient.put(m,lr * r.gethBias().get(m));
      for (int n=0; n < prevR.getNumFilters()[0]; n++) {
        if (useRegularization) {
          DoubleMatrix penalty=r.getFeatureMap().getSliceOfTensor(m,n).mul(l2);
          if (useAdaGrad) {
            DoubleMatrix learningRates=wAdaGrad.getLearningRates(m,n,wGradient.getSliceOfTensor(m,n));
            penalty.muli(learningRates);
          }
 else           penalty.muli(lr);
          wGradient.put(m,n,wGradient.getSliceOfTensor(m,n).mul(penalty));
        }
      }
    }
    DoubleMatrix gradientChange=deltas.get(l).getFirst();
    if (isUseAdaGrad())     gradientChange.muli(getLayers()[l].getAdaGrad().getLearningRates(gradientChange));
 else     gradientChange.muli(lr);
    if (useRegularization)     gradientChange.muli(getLayers()[l].getW().mul(l2));
    if (momentum != 0)     gradientChange.muli(momentum);
    if (isNormalizeByInputRows())     gradientChange.divi(input.rows);
    getLayers()[l].getW().subi(gradientChange);
    getSigmoidLayers()[l].setW(layers[l].getW());
    DoubleMatrix deltaColumnSums=deltas.get(l + 1).getSecond().columnSums();
    if (sparsity != 0)     deltaColumnSums=MatrixUtil.scalarMinus(sparsity,deltaColumnSums);
    if (useAdaGrad)     deltaColumnSums.muli(layers[l].gethBiasAdaGrad().getLearningRates(deltaColumnSums));
 else     deltaColumnSums.muli(lr);
    if (momentum != 0)     deltaColumnSums.muli(momentum);
    if (isNormalizeByInputRows())     deltaColumnSums.divi(input.rows);
    getLayers()[l].gethBias().subi(deltaColumnSums);
    getSigmoidLayers()[l].setB(getLayers()[l].gethBias());
  }
  DoubleMatrix logLayerGradient=deltas.get(getnLayers()).getFirst();
  DoubleMatrix biasGradient=deltas.get(getnLayers()).getSecond().columnSums();
  if (momentum != 0)   logLayerGradient.muli(momentum);
  if (useAdaGrad)   logLayerGradient.muli(outputLayer.getAdaGrad().getLearningRates(logLayerGradient));
 else   logLayerGradient.muli(lr);
  if (isNormalizeByInputRows())   logLayerGradient.divi(input.rows);
  if (momentum != 0)   biasGradient.muli(momentum);
  if (useAdaGrad)   biasGradient.muli(outputLayer.getBiasAdaGrad().getLearningRates(biasGradient));
 else   biasGradient.muli(lr);
  if (isNormalizeByInputRows())   biasGradient.divi(input.rows);
  getOutputLayer().getW().subi(logLayerGradient);
  if (getOutputLayer().getB().length == biasGradient.length)   getOutputLayer().getB().subi(biasGradient);
 else   getOutputLayer().getB().subi(biasGradient.mean());
}
