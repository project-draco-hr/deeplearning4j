{
  SentenceIterator iter=new BasicLineIterator(inputFile.getAbsolutePath());
  TokenizerFactory t=new DefaultTokenizerFactory();
  t.setTokenPreProcessor(new CommonPreprocessor());
  Word2Vec vec=new Word2Vec.Builder().minWordFrequency(1).iterations(5).batchSize(250).layerSize(150).stopWords(new ArrayList<String>()).seed(42).learningRate(0.025).minLearningRate(0.001).sampling(0).negativeSample(10).epochs(1).windowSize(5).modelUtils(new BasicModelUtils<VocabWord>()).iterate(iter).setVectorsListeners(new ArrayList<VectorsListener<VocabWord>>(Collections.singletonList(new ScoreListener<VocabWord>(ListenerEvent.ITERATION,10)))).tokenizerFactory(t).build();
  assertEquals(new ArrayList<String>(),vec.getStopWords());
  vec.fit();
  File tempFile=File.createTempFile("temp","temp");
  tempFile.deleteOnExit();
  WordVectorSerializer.writeFullModel(vec,tempFile.getAbsolutePath());
  Collection<String> lst=vec.wordsNearest("day",10);
  printWords("day",lst,vec);
  assertEquals(10,lst.size());
  double sim=vec.similarity("day","night");
  log.info("Day/night similarity: " + sim);
  assertTrue(sim < 1.0);
  assertTrue(sim > 0.4);
  assertTrue(lst.contains("week"));
  assertTrue(lst.contains("night"));
  assertTrue(lst.contains("year"));
  assertFalse(lst.contains(null));
  lst=vec.wordsNearest("day",10);
  printWords("day",lst,vec);
  assertTrue(lst.contains("week"));
  assertTrue(lst.contains("night"));
  assertTrue(lst.contains("year"));
  new File("cache.ser").delete();
}
