{
  SentenceIterator iter=new BasicLineIterator(inputFile.getAbsolutePath());
  TokenizerFactory t=new DefaultTokenizerFactory();
  t.setTokenPreProcessor(new CommonPreprocessor());
  InMemoryLookupCache cache=new InMemoryLookupCache();
  WeightLookupTable table=new InMemoryLookupTable.Builder().vectorLength(100).useAdaGrad(false).cache(cache).lr(0.025f).build();
  Word2Vec vec=new Word2Vec.Builder().minWordFrequency(5).iterations(1).layerSize(100).lookupTable(table).stopWords(new ArrayList<String>()).vocabCache(cache).seed(42).sampling(0).windowSize(5).modelUtils(new BasicModelUtils<VocabWord>()).iterate(iter).tokenizerFactory(t).build();
  assertEquals(new ArrayList<String>(),vec.getStopWords());
  vec.fit();
  WordVectorSerializer.writeWordVectors(vec,pathToWriteto);
  Collection<String> lst=vec.wordsNearest("day",10);
  log.info(Arrays.toString(lst.toArray()));
  assertEquals(10,lst.size());
  double sim=vec.similarity("day","night");
  log.info("Day/night similarity: " + sim);
  assertTrue(sim < 1.0);
  assertTrue(sim > 0.6);
  assertTrue(lst.contains("week"));
  assertTrue(lst.contains("night"));
  assertTrue(lst.contains("year"));
  assertFalse(lst.contains(null));
  lst=vec.wordsNearestSum("day",10);
  log.info(Arrays.toString(lst.toArray()));
  assertTrue(lst.contains("week"));
  assertTrue(lst.contains("night"));
  assertTrue(lst.contains("year"));
  new File("cache.ser").delete();
}
