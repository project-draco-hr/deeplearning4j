{
  ClassPathResource resource=new ClassPathResource("/tweets_clean.txt");
  InputStream is=resource.getInputStream();
  LabelAwareListSentenceIterator iterator=new LabelAwareListSentenceIterator(is);
  iterator.setPreProcessor(new SentencePreProcessor(){
    @Override public String preProcess(    String sentence){
      return new InputHomogenization(sentence).transform();
    }
  }
);
  TokenizerFactory tokenizerFactory=new UimaTokenizerFactory();
  TextVectorizer vectorizor=new TfidfVectorizer(iterator,tokenizerFactory,Arrays.asList("0","1","2"),2000);
  DataSet data=vectorizor.vectorize();
  log.info("Vocab " + vectorizor.vocab());
  DataSetIterator iter=new ListDataSetIterator(data.asList(),10);
  HazelCastStateTracker tracker=new HazelCastStateTracker();
  Conf c=new Conf();
  c.setFinetuneEpochs(10000);
  c.setFinetuneLearningRate(1e-1);
  c.setLayerSizes(new int[]{iter.inputColumns() / 2,iter.inputColumns() / 4,iter.inputColumns() / 3});
  c.setnIn(iter.inputColumns());
  c.setUseAdaGrad(true);
  c.setnOut(3);
  c.setSplit(10);
  c.setHiddenUnit(RBM.HiddenUnit.RECTIFIED);
  c.setVisibleUnit(RBM.VisibleUnit.GAUSSIAN);
  c.setMultiLayerClazz(DBN.class);
  c.setUseRegularization(false);
  c.setDeepLearningParams(new Object[]{1,1e-1,1000});
  ActorNetworkRunner runner=new ActorNetworkRunner("master",iter);
  runner.setStateTracker(tracker);
  runner.setup(c);
  runner.train();
}
