{
  RandomGenerator rng=new MersenneTwister(123);
  double preTrainLr=0.01;
  int preTrainEpochs=10000;
  int k=1;
  int nIns=4, nOuts=3;
  int[] hiddenLayerSizes=new int[]{4,3,3};
  double fineTuneLr=0.01;
  int fineTuneEpochs=10000;
  GaussianRectifiedLinearDBN dbn=new GaussianRectifiedLinearDBN.Builder().useAdaGrad(true).numberOfInputs(nIns).numberOfOutPuts(nOuts).withActivation(Activations.hardTanh()).hiddenLayerSizes(hiddenLayerSizes).withRng(rng).build();
  DataSetIterator iter=new IrisDataSetIterator(150,150);
  DataSet next=iter.next(150);
  next.normalizeZeroMeanZeroUnitVariance();
  next.shuffle();
  List<DataSet> finetuneBatches=next.dataSetBatches(10);
  DataSetIterator sampling=new SamplingDataSetIterator(next,150,3);
  List<DataSet> miniBatches=new ArrayList<DataSet>();
  while (sampling.hasNext()) {
    next=sampling.next();
    miniBatches.add(next.copy());
  }
  log.info("Training on " + miniBatches.size() + " minibatches");
  for (int i=0; i < miniBatches.size(); i++) {
    DataSet curr=miniBatches.get(i);
    dbn.pretrain(curr.getFirst(),k,preTrainLr,preTrainEpochs);
  }
  Evaluation eval=new Evaluation();
  for (int i=0; i < miniBatches.size(); i++) {
    DataSet curr=miniBatches.get(i);
    dbn.setInput(curr.getFirst());
    dbn.finetune(curr.getSecond(),fineTuneLr,fineTuneEpochs);
  }
  for (int i=0; i < miniBatches.size(); i++) {
    DataSet test=miniBatches.get(i);
    DoubleMatrix predicted=dbn.predict(test.getFirst());
    DoubleMatrix real=test.getSecond();
    eval.eval(real,predicted);
  }
  log.info("Evaled " + eval.stats());
}
