{
  if (layerWiseConfigurations == null || layers == null)   intializeConfigurations();
  if (initCalled)   return;
  INDArray layerInput=input();
  int inputSize;
  if (getnLayers() < 1)   throw new IllegalStateException("Unable to createComplex network neuralNets; number specified is less than 1");
  int[] hiddenLayerSizes=layerWiseConfigurations.getHiddenLayerSizes();
  int numHiddenLayersSizesUsed=0;
  if (this.layers == null || this.layers[0] == null) {
    if (this.layers == null)     this.layers=new Layer[getnLayers()];
    for (int i=0; i < getnLayers(); i++) {
      NeuralNetConfiguration conf=layerWiseConfigurations.getConf(i);
      Layer.Type type=LayerFactories.typeForFactory(conf);
      if (i == 0) {
        inputSize=conf.getNIn();
        if (input == null) {
          input=Nd4j.ones(inputSize);
          layerInput=input;
        }
        conf.setNIn(inputSize);
        if (type == Layer.Type.FEED_FORWARD || type == Layer.Type.RECURRENT) {
          conf.setNOut(hiddenLayerSizes[numHiddenLayersSizesUsed]);
        }
      }
 else       if (i < getLayers().length) {
        if (input != null)         layerInput=activationFromPrevLayer(i - 1,layerInput);
        if (type == Layer.Type.FEED_FORWARD || type == Layer.Type.RECURRENT) {
          if (i != (layers.length - 1)) {
            numHiddenLayersSizesUsed++;
            conf.setNIn(layerInput.size(1));
            conf.setNOut(hiddenLayerSizes[numHiddenLayersSizesUsed]);
          }
 else {
            conf.setNIn(hiddenLayerSizes[numHiddenLayersSizesUsed]);
          }
        }
      }
      layers[i]=LayerFactories.getFactory(conf).create(conf,listeners,i);
    }
    initCalled=true;
    initMask();
  }
}
