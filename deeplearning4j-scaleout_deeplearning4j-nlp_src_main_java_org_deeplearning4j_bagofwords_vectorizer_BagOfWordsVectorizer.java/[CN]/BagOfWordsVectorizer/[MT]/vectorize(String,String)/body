{
  Tokenizer tokenizer=tokenizerFactory.create(text);
  List<String> tokens=tokenizer.getTokens();
  INDArray input=Nd4j.create(1,cache.numWords());
  for (int i=0; i < tokens.size(); i++) {
    int idx=cache.indexOf(tokens.get(i));
    if (cache.indexOf(tokens.get(i)) >= 0)     input.putScalar(idx,cache.wordFrequency(tokens.get(i)));
  }
  INDArray labelMatrix=FeatureUtil.toOutcomeVector(labels.indexOf(label),labels.size());
  return new DataSet(input,labelMatrix);
}
