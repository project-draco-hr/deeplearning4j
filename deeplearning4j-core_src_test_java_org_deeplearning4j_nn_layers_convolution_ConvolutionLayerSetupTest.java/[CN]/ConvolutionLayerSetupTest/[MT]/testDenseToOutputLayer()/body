{
  final int numRows=75;
  final int numColumns=75;
  int nChannels=3;
  int outputNum=6;
  int batchSize=500;
  int iterations=10;
  int seed=123;
  MultiLayerConfiguration.Builder builder=new NeuralNetConfiguration.Builder().seed(seed).batchSize(batchSize).iterations(iterations).regularization(true).l1(1e-1).l2(2e-4).useDropConnect(true).constrainGradientToUnitNorm(true).miniBatch(true).optimizationAlgo(OptimizationAlgorithm.CONJUGATE_GRADIENT).list(6).layer(0,new ConvolutionLayer.Builder(5,5).nOut(5).dropOut(0.5).weightInit(WeightInit.XAVIER).activation("relu").build()).layer(1,new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX,new int[]{2,2}).build()).layer(2,new ConvolutionLayer.Builder(3,3).nOut(10).dropOut(0.5).weightInit(WeightInit.XAVIER).activation("relu").build()).layer(3,new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX,new int[]{2,2}).build()).layer(4,new DenseLayer.Builder().nOut(100).activation("relu").build()).layer(5,new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD).nOut(outputNum).weightInit(WeightInit.XAVIER).activation("softmax").build()).backprop(true).pretrain(false);
  new ConvolutionLayerSetup(builder,numRows,numColumns,nChannels);
  DataSet d=new DataSet(Nd4j.rand(10,3,75,75).reshape(10,3 * 75 * 75),FeatureUtil.toOutcomeMatrix(new int[]{1,1,1,1,1,1,1,1,1,1},6));
  MultiLayerNetwork network=new MultiLayerNetwork(builder.build());
  network.fit(d);
}
