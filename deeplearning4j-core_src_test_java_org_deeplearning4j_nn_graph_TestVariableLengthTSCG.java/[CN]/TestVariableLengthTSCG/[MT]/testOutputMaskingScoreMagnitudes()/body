{
  int nIn=3;
  int[] timeSeriesLengths={3,10};
  int[] outputSizes={1,2,5};
  int[] miniBatchSizes={1,4};
  Random r=new Random(12345);
  for (  int tsLength : timeSeriesLengths) {
    for (    int nOut : outputSizes) {
      for (      int miniBatch : miniBatchSizes) {
        for (int nToMask=0; nToMask < tsLength - 1; nToMask++) {
          String msg="tsLen=" + tsLength + ", nOut="+ nOut+ ", miniBatch="+ miniBatch;
          INDArray labelMaskArray=Nd4j.ones(miniBatch,tsLength);
          for (int i=0; i < miniBatch; i++) {
            int nMasked=0;
            while (nMasked < nToMask) {
              int tryIdx=r.nextInt(tsLength);
              if (labelMaskArray.getDouble(i,tryIdx) == 0.0)               continue;
              labelMaskArray.putScalar(new int[]{i,tryIdx},0.0);
              nMasked++;
            }
          }
          INDArray input=Nd4j.rand(new int[]{miniBatch,nIn,tsLength});
          INDArray labels=Nd4j.ones(miniBatch,nOut,tsLength);
          ComputationGraphConfiguration conf=new NeuralNetConfiguration.Builder().regularization(false).seed(12345L).graphBuilder().addInputs("in").addLayer("0",new GravesLSTM.Builder().nIn(nIn).nOut(5).weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0,1)).updater(Updater.NONE).build(),"in").addLayer("1",new RnnOutputLayer.Builder(LossFunctions.LossFunction.MSE).activation("identity").nIn(5).nOut(nOut).weightInit(WeightInit.ZERO).updater(Updater.NONE).build(),"0").setOutputs("1").pretrain(false).backprop(true).build();
          ComputationGraph net=new ComputationGraph(conf);
          net.init();
          double expScore=0.5 * nOut * (tsLength - nToMask);
          net.setLayerMaskArrays(null,new INDArray[]{labelMaskArray});
          net.setInput(0,input);
          net.setLabel(0,labels);
          net.computeGradientAndScore();
          double score=net.score();
          assertEquals(msg,expScore,score,0.1);
        }
      }
    }
  }
}
