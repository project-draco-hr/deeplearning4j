{
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.LINE_GRADIENT_DESCENT).iterations(1).seed(42).learningRate(1e-6).list(2).layer(0,new DenseLayer.Builder().nIn(4).nOut(2).activation("tanh").weightInit(WeightInit.XAVIER).build()).layer(1,new org.deeplearning4j.nn.conf.layers.OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).nIn(2).nOut(3).weightInit(WeightInit.XAVIER).activation("softmax").build()).build();
  MultiLayerNetwork model=new MultiLayerNetwork(conf);
  model.init();
  model.setListeners(Arrays.asList((IterationListener)new ScoreIterationListener(1)));
  DataSetIterator iter=new IrisDataSetIterator(150,150);
  DataSet next=iter.next();
  next.shuffle();
  SplitTestAndTrain trainTest=next.splitTestAndTrain(5,new Random(42));
  DataSet train=trainTest.getTrain();
  train.normalizeZeroMeanZeroUnitVariance();
  DataSet test=trainTest.getTest();
  test.normalizeZeroMeanZeroUnitVariance();
  INDArray testFeature=test.getFeatureMatrix();
  INDArray testLabel=test.getLabels();
  model.fit(train);
  INDArray testPredictedLabel=model.output(testFeature);
  Evaluation eval=new Evaluation(3);
  eval.eval(testLabel,testPredictedLabel);
  double eval1F1=eval.f1();
  double eval1Acc=eval.accuracy();
  Evaluation eval2=new Evaluation();
  eval2.eval(testLabel,testPredictedLabel);
  double eval2F1=eval2.f1();
  double eval2Acc=eval2.accuracy();
  assertTrue(eval1F1 == eval2F1 && eval1Acc == eval2Acc);
}
