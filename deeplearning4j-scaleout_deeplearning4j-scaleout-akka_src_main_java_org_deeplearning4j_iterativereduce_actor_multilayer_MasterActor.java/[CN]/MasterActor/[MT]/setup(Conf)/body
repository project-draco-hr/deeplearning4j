{
  log.info("Starting workers");
  ActorSystem system=context().system();
  RoundRobinPool pool=new RoundRobinPool(Runtime.getRuntime().availableProcessors());
  Props p=pool.props(WorkerActor.propsFor(conf));
  p=ClusterSingletonManager.defaultProps(p,"master",PoisonPill.getInstance(),"master");
  system.actorOf(p,"worker");
  try {
    Thread.sleep(30000);
  }
 catch (  InterruptedException e) {
    Thread.currentThread().interrupt();
  }
  log.info("Broadcasting initial master network");
  BaseMultiLayerNetwork network=this.network == null ? new BaseMultiLayerNetwork.Builder<>().numberOfInputs(conf.getnIn()).numberOfOutPuts(conf.getnOut()).withClazz(conf.getMultiLayerClazz()).hiddenLayerSizes(conf.getLayerSizes()).renderWeights(conf.getRenderWeightEpochs()).useRegularization(conf.isUseRegularization()).withSparsity(conf.getSparsity()).useAdGrad(conf.isUseAdaGrad()).withMultiLayerGradientListeners(conf.getMultiLayerGradientListeners()).withGradientListeners(conf.getGradientListeners()).build() : this.network;
  if (conf.getColumnMeans() != null)   network.setColumnMeans(conf.getColumnMeans());
  if (conf.getColumnStds() != null)   network.setColumnStds(conf.getColumnStds());
  masterResults=new UpdateableImpl(network);
  mediator.tell(new DistributedPubSubMediator.Publish(BROADCAST,masterResults),getSelf());
  ensureNoLeftOvers=context().system().scheduler().schedule(Duration.create(1,TimeUnit.MINUTES),Duration.create(1,TimeUnit.MINUTES),new Runnable(){
    @Override public void run(){
      log.info("Status check on next iteration");
      if (!updates.isEmpty() && currentJobs.isEmpty() || everyWorkerAvailable()) {
        log.info("Forcing next iteration");
        nextIteration();
      }
 else {
        for (        Job j : currentJobs.values()) {
          mediator.tell(new DistributedPubSubMediator.Publish(j.getWorkerId(),NeedsStatus.getInstance()),getSelf());
        }
      }
      log.info("Available workers " + availableWorkers);
      log.info("Current jobs left " + currentJobs.keySet());
    }
  }
,context().dispatcher());
  ensureDistribution=context().system().scheduler().schedule(Duration.create(1,TimeUnit.MINUTES),Duration.create(1,TimeUnit.MINUTES),new Runnable(){
    @Override public void run(){
      for (      final Job j : needsToBeRedistributed) {
        scala.concurrent.Future<Void> f=Futures.future(new Callable<Void>(){
          @Override public Void call() throws Exception {
            WorkerState state=workers.get(j.getWorkerId());
            if (state != null) {
              state.setAvailable(true);
              log.info("Worker " + state.getWorkerId() + " unavailable for work");
              if (j != null) {
                log.info("Redispatching work for id " + j.getWorkerId());
                scala.concurrent.Future<WorkerState> f=Futures.future(new Callable<WorkerState>(){
                  @Override public WorkerState call() throws Exception {
                    log.info("Fetching new worker...");
                    WorkerState worker=nextAvailableWorker();
                    return worker;
                  }
                }
,context().dispatcher());
                f.onComplete(new OnComplete<WorkerState>(){
                  @Override public void onComplete(                  Throwable arg0,                  WorkerState worker) throws Throwable {
                    if (arg0 != null)                     throw arg0;
                    log.info("Found new worker ");
                    j.setWorkerId(worker.getWorkerId());
                    mediator.tell(new DistributedPubSubMediator.Publish(worker.getWorkerId(),j),getSelf());
                    log.info("Delegated work to worker " + worker.getWorkerId());
                  }
                }
,context().dispatcher());
              }
            }
            return null;
          }
        }
,context().dispatcher());
        ActorRefUtils.throwExceptionIfExists(f,context().dispatcher());
      }
    }
  }
,context().dispatcher());
}
