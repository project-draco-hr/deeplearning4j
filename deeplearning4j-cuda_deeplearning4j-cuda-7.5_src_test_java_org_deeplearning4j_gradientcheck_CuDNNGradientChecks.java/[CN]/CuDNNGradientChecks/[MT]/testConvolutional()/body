{
  String[] activFns={"sigmoid","tanh"};
  boolean[] characteristic={false,true};
  int[] minibatchSizes={1,4};
  int width=5;
  int height=5;
  int inputDepth=2;
  int nOut=3;
  Field f=org.deeplearning4j.nn.layers.convolution.ConvolutionLayer.class.getDeclaredField("helper");
  f.setAccessible(true);
  Random r=new Random(12345);
  for (  String afn : activFns) {
    for (    boolean doLearningFirst : characteristic) {
      for (      int minibatchSize : minibatchSizes) {
        INDArray input=Nd4j.rand(minibatchSize,inputDepth,height,width);
        INDArray labels=Nd4j.zeros(minibatchSize,nOut);
        for (int i=0; i < minibatchSize; i++) {
          labels.putScalar(i,r.nextInt(nOut),1.0);
        }
        MultiLayerConfiguration.Builder builder=new NeuralNetConfiguration.Builder().regularization(false).optimizationAlgo(OptimizationAlgorithm.CONJUGATE_GRADIENT).weightInit(WeightInit.DISTRIBUTION).dist(new UniformDistribution(-1,1)).updater(Updater.NONE).seed(12345L).list().layer(0,new ConvolutionLayer.Builder(2,2).stride(1,1).padding(1,1).nOut(3).activation(afn).build()).layer(0,new ConvolutionLayer.Builder(2,2).stride(2,2).padding(0,0).nOut(3).activation(afn).build()).layer(1,new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation("softmax").nOut(nOut).build()).setInputType(InputType.convolutionalFlat(1,4,1)).pretrain(false).backprop(true);
        MultiLayerConfiguration conf=builder.build();
        MultiLayerNetwork mln=new MultiLayerNetwork(conf);
        mln.init();
        org.deeplearning4j.nn.layers.convolution.ConvolutionLayer c0=(org.deeplearning4j.nn.layers.convolution.ConvolutionLayer)mln.getLayer(0);
        ConvolutionHelper ch0=(ConvolutionHelper)f.get(c0);
        assertTrue(ch0 instanceof CudnnConvolutionHelper);
        org.deeplearning4j.nn.layers.convolution.ConvolutionLayer c1=(org.deeplearning4j.nn.layers.convolution.ConvolutionLayer)mln.getLayer(1);
        ConvolutionHelper ch1=(ConvolutionHelper)f.get(c1);
        assertTrue(ch1 instanceof CudnnConvolutionHelper);
        String name=new Object(){
        }
.getClass().getEnclosingMethod().getName();
        if (doLearningFirst) {
          mln.setInput(input);
          mln.setLabels(labels);
          mln.computeGradientAndScore();
          double scoreBefore=mln.score();
          for (int j=0; j < 10; j++)           mln.fit(input,labels);
          mln.computeGradientAndScore();
          double scoreAfter=mln.score();
          String msg=name + " - score did not (sufficiently) decrease during learning - activationFn=" + afn+ ", doLearningFirst= "+ doLearningFirst+ " (before="+ scoreBefore+ ", scoreAfter="+ scoreAfter+ ")";
          assertTrue(msg,scoreAfter < 0.8 * scoreBefore);
        }
        if (PRINT_RESULTS) {
          System.out.println(name + " - activationFn=" + afn+ ", doLearningFirst="+ doLearningFirst);
          for (int j=0; j < mln.getnLayers(); j++)           System.out.println("Layer " + j + " # params: "+ mln.getLayer(j).numParams());
        }
        boolean gradOK=GradientCheckUtil.checkGradients(mln,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,input,labels);
        assertTrue(gradOK);
      }
    }
  }
}
