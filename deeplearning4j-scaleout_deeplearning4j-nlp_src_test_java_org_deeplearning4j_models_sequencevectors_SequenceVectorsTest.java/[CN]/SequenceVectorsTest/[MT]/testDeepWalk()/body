{
  Heartbeat.getInstance().disableHeartbeat();
  AbstractCache<Blogger> vocabCache=new AbstractCache.Builder<Blogger>().build();
  Graph<Blogger,Double> graph=buildGraph();
  GraphWalker<Blogger> walker=new PopularityWalker.Builder<>(graph).setNoEdgeHandling(NoEdgeHandling.RESTART_ON_DISCONNECTED).setWalkLength(40).setWalkDirection(WalkDirection.FORWARD_UNIQUE).setRestartProbability(0.05).setPopularitySpread(10).setPopularityMode(PopularityMode.MAXIMUM).setSpreadSpectrum(SpreadSpectrum.PROPORTIONAL).build();
  GraphTransformer<Blogger> graphTransformer=new GraphTransformer.Builder<Blogger>(graph).setGraphWalker(walker).shuffleOnReset(true).setVocabCache(vocabCache).build();
  Blogger blogger=graph.getVertex(0).getValue();
  assertEquals(119,blogger.getElementFrequency(),0.001);
  logger.info("Blogger: " + blogger);
  AbstractSequenceIterator<Blogger> sequenceIterator=new AbstractSequenceIterator.Builder<Blogger>(graphTransformer).build();
  WeightLookupTable<Blogger> lookupTable=new InMemoryLookupTable.Builder<Blogger>().lr(0.025).vectorLength(150).useAdaGrad(false).cache(vocabCache).seed(42).build();
  lookupTable.resetWeights(true);
  SequenceVectors<Blogger> vectors=new SequenceVectors.Builder<Blogger>(new VectorsConfiguration()).lookupTable(lookupTable).iterate(sequenceIterator).vocabCache(vocabCache).batchSize(1000).iterations(1).epochs(10).resetModel(false).trainElementsRepresentation(true).trainSequencesRepresentation(false).elementsLearningAlgorithm(new SkipGram<Blogger>()).learningRate(0.025).layerSize(150).sampling(0).negativeSample(0).windowSize(4).workers(6).seed(42).build();
  vectors.fit();
  vectors.setModelUtils(new FlatModelUtils());
  double sim=vectors.similarity("12","72");
  Collection<String> list=vectors.wordsNearest("12",20);
  logger.info("12->72: " + sim);
  printWords("12",list,vectors);
  assertTrue(sim > 0.10);
  assertFalse(Double.isNaN(sim));
}
