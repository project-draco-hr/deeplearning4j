{
  AbstractCache<Blogger> vocabCache=new AbstractCache.Builder<Blogger>().build();
  Graph<Blogger,Void> graph=buildGraph();
  GraphTransformer<Blogger> graphTransformer=new GraphTransformer.Builder<Blogger>(graph).setWalkMode(WalkMode.RANDOM).setNoEdgeHandling(NoEdgeHandling.CUTOFF_ON_DISCONNECTED).setWalkLength(10).setWalkDirection(WalkDirection.FORWARD_ONLY).shuffleOnReset(true).setVocabCache(vocabCache).build();
  AbstractSequenceIterator<Blogger> sequenceIterator=new AbstractSequenceIterator.Builder<Blogger>(graphTransformer).build();
  WeightLookupTable<Blogger> lookupTable=new InMemoryLookupTable.Builder<Blogger>().lr(0.025).vectorLength(150).useAdaGrad(false).cache(vocabCache).build();
  lookupTable.resetWeights(true);
  SequenceVectors<Blogger> vectors=new SequenceVectors.Builder<Blogger>(new VectorsConfiguration()).lookupTable(lookupTable).iterate(sequenceIterator).vocabCache(vocabCache).batchSize(250).iterations(1).epochs(5).resetModel(false).trainElementsRepresentation(true).trainSequencesRepresentation(false).elementsLearningAlgorithm(new SkipGram<Blogger>()).windowSize(10).build();
  vectors.fit();
  vectors.setModelUtils(new BasicModelUtils());
  double sim=vectors.similarity("12","72");
  Collection<String> list=vectors.wordsNearest("12",10);
  logger.info("12->72: " + sim);
  printWords("12",list,vectors);
  assertTrue(sim > 0.10);
  assertFalse(Double.isNaN(sim));
}
