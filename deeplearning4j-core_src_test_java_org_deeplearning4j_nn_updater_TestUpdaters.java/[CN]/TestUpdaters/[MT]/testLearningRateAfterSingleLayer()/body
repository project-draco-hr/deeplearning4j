{
  double lr=1e-2;
  Map<Integer,Double> learningRateAfter=new HashMap<>();
  learningRateAfter.put(1,0.2);
  int iterations=2;
  NeuralNetConfiguration conf=new NeuralNetConfiguration.Builder().learningRate(lr).learningRateAfter(learningRateAfter).schedules(true).iterations(iterations).layer(new DenseLayer.Builder().nIn(nIn).nOut(nOut).updater(org.deeplearning4j.nn.conf.Updater.SGD).build()).build();
  Layer layer=LayerFactories.getFactory(conf).create(conf,null,0);
  Updater updater=UpdaterCreator.getUpdater(layer);
  Gradient gradientDup=new DefaultGradient();
  gradientDup.setGradientFor(DefaultParamInitializer.WEIGHT_KEY,weightGradient);
  gradientDup.setGradientFor(DefaultParamInitializer.BIAS_KEY,biasGradient);
  for (int i=0; i < 2; i++) {
    updater.update(layer,gradient,i);
    for (    Map.Entry<String,INDArray> entry : gradientDup.gradientForVariable().entrySet()) {
      if (learningRateAfter != null)       lr=(learningRateAfter.containsKey(i)) ? learningRateAfter.get(i) : lr;
      key=entry.getKey();
      val=entry.getValue();
      gradExpected=val.mul(lr);
      gradientDup.setGradientFor(key,gradExpected);
      assertEquals(gradExpected,gradient.getGradientFor(key));
    }
    assertEquals(lr,layer.conf().getLayer().getLearningRate(),1e-4);
  }
}
