{
  Nd4j.getRandom().setSeed(12345L);
  double lr=0.03;
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().learningRate(lr).momentum(0.6).list().layer(0,new DenseLayer.Builder().nIn(4).nOut(5).updater(org.deeplearning4j.nn.conf.Updater.SGD).build()).layer(1,new DenseLayer.Builder().nIn(5).nOut(6).updater(org.deeplearning4j.nn.conf.Updater.NONE).build()).layer(2,new DenseLayer.Builder().nIn(6).nOut(7).updater(org.deeplearning4j.nn.conf.Updater.ADAGRAD).build()).layer(3,new DenseLayer.Builder().nIn(7).nOut(8).updater(org.deeplearning4j.nn.conf.Updater.NESTEROVS).build()).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  net.init();
  Updater updater=UpdaterCreator.getUpdater(net);
  assertNotNull(updater);
  assertTrue(updater.getClass() == MultiLayerUpdater.class);
  Field f=MultiLayerUpdater.class.getDeclaredField("layerUpdaters");
  f.setAccessible(true);
  Updater[] updaters=(Updater[])f.get(updater);
  assertNotNull(updaters);
  assertTrue(updaters.length == net.getnLayers());
  assertTrue(updaters[0] instanceof SgdUpdater);
  assertTrue(updaters[1] instanceof NoOpUpdater);
  assertTrue(updaters[2] instanceof AdaGradUpdater);
  assertTrue(updaters[3] instanceof NesterovsUpdater);
  Updater[] uArr=new Updater[4];
  uArr[0]=new SgdUpdater();
  uArr[1]=new NoOpUpdater();
  uArr[2]=new AdaGradUpdater();
  uArr[3]=new NesterovsUpdater();
  int[] nIns={4,5,6,7};
  int[] nOuts={5,6,7,8};
  for (int i=0; i < 5; i++) {
    Gradient gradient=new DefaultGradient();
    Map<String,INDArray> expectedGradient=new HashMap<>();
    for (int j=0; j < net.getnLayers(); j++) {
      INDArray wGrad=Nd4j.rand(nIns[j],nOuts[j]);
      INDArray bGrad=Nd4j.rand(1,nOuts[j]);
      String wKey=j + "_" + DefaultParamInitializer.WEIGHT_KEY;
      String bKey=j + "_" + DefaultParamInitializer.BIAS_KEY;
      gradient.setGradientFor(wKey,wGrad);
      gradient.setGradientFor(bKey,bGrad);
      Gradient layerGradient=new DefaultGradient();
      layerGradient.setGradientFor(DefaultParamInitializer.WEIGHT_KEY,wGrad.dup());
      layerGradient.setGradientFor(DefaultParamInitializer.BIAS_KEY,bGrad.dup());
      uArr[j].update(net.getLayer(j),layerGradient,i,1);
      for (      String s : layerGradient.gradientForVariable().keySet()) {
        expectedGradient.put(j + "_" + s,layerGradient.getGradientFor(s));
      }
    }
    updater.update(net,gradient,i,1);
    assertTrue(gradient.gradientForVariable().equals(expectedGradient));
  }
}
