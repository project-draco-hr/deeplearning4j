{
  currScore=0.0;
  for (int i=0; i < input.rows(); i++) {
    INDArray combined=currInput == null ? Nd4j.concat(0,input.slice(i),input.slice(i + 1)) : Nd4j.concat(0,input.slice(i),currInput);
    if (i == 0) {
      i++;
    }
    currInput=combined;
    allInput=combined;
    INDArray encoded=activate(combined);
    y=decode(encoded);
    INDArray currVisibleLoss=currInput.sub(y);
    INDArray currHiddenLoss=currVisibleLoss.mmul(getParam(RecursiveParamInitializer.ENCODER_WEIGHT_KEY)).muli(encoded).muli(encoded.rsub(1));
    INDArray hiddenGradient=y.transpose().mmul(currHiddenLoss);
    INDArray visibleGradient=encoded.transpose().mmul(currVisibleLoss);
    if (visibleLoss == null)     visibleLoss=visibleGradient;
 else     visibleLoss.addi(visibleGradient);
    if (hiddenLoss == null)     hiddenLoss=hiddenGradient;
 else     hiddenLoss.addi(hiddenGradient);
    INDArray currCLoss=currVisibleLoss.isMatrix() ? currVisibleLoss.mean(0) : currVisibleLoss;
    INDArray currBLoss=currHiddenLoss.isMatrix() ? currHiddenLoss.mean(0) : currHiddenLoss;
    if (cLoss == null)     cLoss=currCLoss;
 else     cLoss.addi(currCLoss);
    if (bLoss == null)     bLoss=currBLoss;
 else     bLoss.addi(currBLoss);
    currScore+=scoreSnapShot();
  }
  return createGradient(hiddenLoss,visibleLoss,cLoss,bLoss);
}
