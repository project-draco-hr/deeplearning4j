{
  JavaSparkContext sc=getContext();
  File f=new File("src/test/resources/imagetest/0/a.bmp");
  List<String> labelsList=Arrays.asList("0","1");
  String path=f.getPath();
  String folder=path.substring(0,path.length() - 7);
  path=folder + "*";
  JavaPairRDD<String,PortableDataStream> origData=sc.binaryFiles(path);
  assertEquals(4,origData.count());
  ImageRecordReader rr=new ImageRecordReader(28,28,1,new ParentPathLabelGenerator());
  rr.setLabels(labelsList);
  org.datavec.spark.functions.RecordReaderFunction rrf=new org.datavec.spark.functions.RecordReaderFunction(rr);
  JavaRDD<List<Writable>> rdd=origData.map(rrf);
  JavaRDD<DataSet> data=rdd.map(new DataVecDataSetFunction(1,2,false));
  List<DataSet> collected=data.collect();
  InputSplit is=new FileSplit(new File(folder),new String[]{"bmp"},true);
  ImageRecordReader irr=new ImageRecordReader(28,28,1,new ParentPathLabelGenerator());
  irr.initialize(is);
  RecordReaderDataSetIterator iter=new RecordReaderDataSetIterator(irr,1,1,2);
  List<DataSet> listLocal=new ArrayList<>(4);
  while (iter.hasNext()) {
    listLocal.add(iter.next());
  }
  assertEquals(4,collected.size());
  assertEquals(4,listLocal.size());
  boolean[] found=new boolean[4];
  for (int i=0; i < 4; i++) {
    int foundIndex=-1;
    DataSet ds=collected.get(i);
    for (int j=0; j < 4; j++) {
      if (ds.equals(listLocal.get(j))) {
        if (foundIndex != -1)         fail();
        foundIndex=j;
        if (found[foundIndex])         fail();
        found[foundIndex]=true;
      }
    }
  }
  int count=0;
  for (  boolean b : found)   if (b)   count++;
  assertEquals(4,count);
}
