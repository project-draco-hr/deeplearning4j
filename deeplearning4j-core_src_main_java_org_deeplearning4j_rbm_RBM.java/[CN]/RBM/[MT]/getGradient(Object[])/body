{
  int k=(int)params[0];
  double learningRate=(double)params[1];
  if (wAdaGrad != null)   wAdaGrad.setMasterStepSize(learningRate);
  if (hBiasAdaGrad != null)   hBiasAdaGrad.setMasterStepSize(learningRate);
  if (vBiasAdaGrad != null)   vBiasAdaGrad.setMasterStepSize(learningRate);
  Pair<DoubleMatrix,DoubleMatrix> probHidden=sampleHiddenGivenVisible(input);
  DoubleMatrix chainStart=probHidden.getSecond();
  Pair<Pair<DoubleMatrix,DoubleMatrix>,Pair<DoubleMatrix,DoubleMatrix>> matrices=null;
  DoubleMatrix nvMeans=null;
  DoubleMatrix nvSamples=null;
  DoubleMatrix nhMeans=null;
  DoubleMatrix nhSamples=null;
  for (int i=0; i < k; i++) {
    if (i == 0)     matrices=gibbhVh(chainStart);
 else     matrices=gibbhVh(nhSamples);
    nvMeans=matrices.getFirst().getFirst();
    nvSamples=matrices.getFirst().getSecond();
    nhMeans=matrices.getSecond().getFirst();
    nhSamples=matrices.getSecond().getSecond();
  }
  DoubleMatrix wGradient=input.transpose().mmul(probHidden.getSecond()).sub(nvSamples.transpose().mmul(nhMeans));
  DoubleMatrix hBiasGradient=null;
  if (sparsity != 0)   hBiasGradient=mean(scalarMinus(sparsity,probHidden.getSecond()),0);
 else   hBiasGradient=mean(probHidden.getSecond().sub(nhMeans),0);
  DoubleMatrix vBiasGradient=mean(input.sub(nvSamples),0);
  NeuralNetworkGradient ret=new NeuralNetworkGradient(wGradient,vBiasGradient,hBiasGradient);
  updateGradientAccordingToParams(ret,learningRate);
  return ret;
}
