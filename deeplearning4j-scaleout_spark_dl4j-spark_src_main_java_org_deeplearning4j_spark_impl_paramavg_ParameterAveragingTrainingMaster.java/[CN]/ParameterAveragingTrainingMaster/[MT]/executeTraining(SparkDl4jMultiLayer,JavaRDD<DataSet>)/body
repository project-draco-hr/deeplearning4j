{
  if (collectTrainingStats)   stats.logFitStart();
  trainingData.persist(StorageLevel.MEMORY_ONLY());
  long totalDataSetObjectCount=trainingData.count();
  int dataSetObjectsPerSplit=getNumDataSetObjectsPerSplit();
  if (collectTrainingStats)   stats.logSplitStart();
  JavaRDD<DataSet>[] splits=SparkUtils.balancedRandomSplit((int)totalDataSetObjectCount,dataSetObjectsPerSplit,trainingData);
  for (int i=0; i < splits.length; i++) {
    System.out.println("SPLIT: " + i + ", SIZE (nObjects) = "+ splits[i].collect().size());
  }
  if (collectTrainingStats)   stats.logSplitEnd();
  int splitNum=1;
  for (  JavaRDD<DataSet> split : splits) {
    doIteration(network,split,splitNum++,splits.length);
  }
  if (collectTrainingStats)   stats.logFitEnd((int)totalDataSetObjectCount);
}
