{
  if (numWorkers == null)   numWorkers=network.getSparkContext().defaultParallelism();
  if (collectTrainingStats)   stats.logFitStart();
  if (storageLevelStreams != null)   trainingMultiDataPaths.persist(storageLevelStreams);
  if (collectTrainingStats)   stats.logCountStart();
  long totalDataSetObjectCount=trainingMultiDataPaths.count();
  if (collectTrainingStats)   stats.logCountEnd();
  int dataSetObjectsPerSplit=getNumDataSetObjectsPerSplit(dataSetObjectsNumExamples);
  if (collectTrainingStats)   stats.logSplitStart();
  JavaRDD<String>[] splits=SparkUtils.balancedRandomSplit((int)totalDataSetObjectCount,dataSetObjectsPerSplit,trainingMultiDataPaths,rng.nextLong());
  if (collectTrainingStats)   stats.logSplitEnd();
  int splitNum=1;
  for (  JavaRDD<String> split : splits) {
    doIterationPathsMDS(network,split,splitNum++,splits.length,dataSetObjectsNumExamples);
  }
  if (collectTrainingStats)   stats.logFitEnd((int)totalDataSetObjectCount);
}
