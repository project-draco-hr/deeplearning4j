{
  log.info("Starting training of split {} of {}. workerMiniBatchSize={}, averagingFreq={}, Configured for {} workers",splitNum,numSplits,batchSizePerWorker,averagingFrequency,numWorkers);
  if (collectTrainingStats)   stats.logMapPartitionsStart();
  JavaRDD<DataSet> splitData=split;
  if (collectTrainingStats)   stats.logRepartitionStart();
  splitData=SparkUtils.repartition(splitData,repartition,repartitionStrategy,numObjectsEachWorker(rddDataSetNumExamples),numWorkers);
  int nPartitions=splitData.partitions().size();
  if (collectTrainingStats && repartition != Repartition.Never)   stats.logRepartitionEnd();
  FlatMapFunction<Iterator<DataSet>,ParameterAveragingTrainingResult> function=new ExecuteWorkerFlatMap<>(getWorkerInstance(network));
  JavaRDD<ParameterAveragingTrainingResult> result=splitData.mapPartitions(function);
  processResults(network,null,result,splitNum,numSplits);
  if (collectTrainingStats)   stats.logMapPartitionsEnd(nPartitions);
}
