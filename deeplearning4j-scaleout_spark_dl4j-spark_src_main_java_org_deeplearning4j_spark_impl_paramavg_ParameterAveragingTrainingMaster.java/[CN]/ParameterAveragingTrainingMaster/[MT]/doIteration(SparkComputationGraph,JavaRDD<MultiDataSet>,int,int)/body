{
  log.info("Starting training of split {} of {}. workerMiniBatchSize={}, averagingFreq={}, Configured for {} workers",splitNum,numSplits,batchSizePerWorker,averagingFrequency,numWorkers);
  if (collectTrainingStats)   stats.logMapPartitionsStart();
  JavaRDD<MultiDataSet> splitData=split;
  splitData=SparkUtils.repartition(splitData,repartition,repartitionStrategy,numObjectsEachWorker(rddDataSetNumExamples),numWorkers);
  int nPartitions=split.partitions().size();
  FlatMapFunction<Iterator<MultiDataSet>,ParameterAveragingTrainingResult> function=new ExecuteWorkerMultiDataSetFlatMap<>(getWorkerInstance(graph));
  JavaRDD<ParameterAveragingTrainingResult> result=splitData.mapPartitions(function);
  processResults(null,graph,result,splitNum,numSplits);
  if (collectTrainingStats)   stats.logMapPartitionsEnd(nPartitions);
}
