{
  Map<String,INDArray> params=Collections.synchronizedMap(new LinkedHashMap<String,INDArray>());
  org.deeplearning4j.nn.conf.layers.GravesLSTM layerConf=(org.deeplearning4j.nn.conf.layers.GravesLSTM)conf.getLayer();
  double forgetGateInit=layerConf.getForgetGateBiasInit();
  Distribution dist=Distributions.createDistribution(layerConf.getDist());
  int nL=layerConf.getNOut();
  int nLast=layerConf.getNIn();
  conf.addVariable(INPUT_WEIGHT_KEY);
  conf.addVariable(RECURRENT_WEIGHT_KEY);
  conf.addVariable(BIAS_KEY);
  int length=numParams(conf,true);
  if (paramsView.length() != length)   throw new IllegalStateException("Expected params view of length " + length + ", got length "+ paramsView.length());
  int nParamsIn=nLast * (4 * nL);
  int nParamsRecurrent=nL * (4 * nL + 3);
  int nBias=4 * nL;
  INDArray inputWeightView=paramsView.get(NDArrayIndex.point(0),NDArrayIndex.interval(0,nParamsIn));
  INDArray recurrentWeightView=paramsView.get(NDArrayIndex.point(0),NDArrayIndex.interval(nParamsIn,nParamsIn + nParamsRecurrent));
  INDArray biasView=paramsView.get(NDArrayIndex.point(0),NDArrayIndex.interval(nParamsIn + nParamsRecurrent,nParamsIn + nParamsRecurrent + nBias));
  if (initializeParams) {
    params.put(INPUT_WEIGHT_KEY,WeightInitUtil.initWeights(nLast,4 * nL,layerConf.getWeightInit(),dist,inputWeightView));
    params.put(RECURRENT_WEIGHT_KEY,WeightInitUtil.initWeights(nL,4 * nL + 3,layerConf.getWeightInit(),dist,recurrentWeightView));
    biasView.put(new INDArrayIndex[]{NDArrayIndex.point(0),NDArrayIndex.interval(nL,2 * nL)},Nd4j.ones(1,nL).muli(forgetGateInit));
    params.put(BIAS_KEY,biasView);
  }
 else {
    params.put(INPUT_WEIGHT_KEY,WeightInitUtil.reshapeWeights(new int[]{nLast,4 * nL},inputWeightView));
    params.put(RECURRENT_WEIGHT_KEY,WeightInitUtil.reshapeWeights(new int[]{nL,4 * nL + 3},recurrentWeightView));
    params.put(BIAS_KEY,biasView);
  }
  return params;
}
