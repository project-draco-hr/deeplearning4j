{
  SparkConf sparkConf=new SparkConf().setMaster("local[*]").setAppName("sparktest");
  JavaSparkContext sc=new JavaSparkContext(sparkConf);
  String dataPath=new ClassPathResource("raw_sentences.txt").getFile().getAbsolutePath();
  JavaRDD<String> corpus=sc.textFile(dataPath);
  Word2Vec word2Vec=new Word2Vec().setnGrams(1).setTokenizer("org.deeplearning4j.text.tokenization.tokenizerfactory.DefaultTokenizerFactory").setTokenPreprocessor("org.deeplearning4j.text.tokenization.tokenizer.preprocessor.CommonPreprocessor").setRemoveStop(false).setSeed(42L).setNegative(0).setUseAdaGrad(false).setVectorLength(100).setWindow(5).setAlpha(0.055).setMinAlpha(0.001).setIterations(3).setNumWords(5);
  word2Vec.train(corpus);
  Collection<String> words=word2Vec.wordsNearest("day",10);
  System.out.println(words);
  sc.stop();
}
