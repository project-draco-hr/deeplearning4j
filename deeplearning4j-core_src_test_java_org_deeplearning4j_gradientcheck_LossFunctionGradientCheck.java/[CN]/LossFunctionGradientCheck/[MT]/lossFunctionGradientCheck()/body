{
  ILossFunction[] lossFunctions=new ILossFunction[]{new LossBinaryXENT(),new LossCosineProximity(),new LossHinge(),new LossKLD(),new LossKLD(),new LossMAE(),new LossMAE(),new LossMAPE(),new LossMAPE(),new LossMCXENT(),new LossMSE(),new LossMSE(),new LossMSLE(),new LossMSLE(),new LossNegativeLogLikelihood(),new LossNegativeLogLikelihood(),new LossPoisson(),new LossSquaredHinge()};
  String[] outputActivationFn=new String[]{"sigmoid","tanh","tanh","sigmoid","softmax","identity","softmax","identity","softmax","softmax","identity","softmax","sigmoid","softmax","sigmoid","softmax","sigmoid","tanh"};
  int[] nOut=new int[]{1,5,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3};
  int[] minibatchSizes=new int[]{1,4};
  List<String> passed=new ArrayList<>();
  List<String> failed=new ArrayList<>();
  for (int i=0; i < lossFunctions.length; i++) {
    for (int j=0; j < minibatchSizes.length; j++) {
      String testName=lossFunctions[i] + " - " + outputActivationFn[i]+ " - minibatchSize = "+ minibatchSizes[j];
      Nd4j.getRandom().setSeed(12345);
      MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().iterations(1).optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).seed(12345).updater(Updater.NONE).regularization(false).weightInit(WeightInit.DISTRIBUTION).dist(new UniformDistribution(-2,2)).list().layer(0,new DenseLayer.Builder().nIn(4).nOut(4).activation("tanh").build()).layer(1,new OutputLayer.Builder().lossFunction(lossFunctions[i]).activation(outputActivationFn[i]).nIn(4).nOut(nOut[i]).build()).pretrain(false).backprop(true).build();
      MultiLayerNetwork net=new MultiLayerNetwork(conf);
      net.init();
      INDArray[] inOut=getFeaturesAndLabels(lossFunctions[i],minibatchSizes[j],4,nOut[i],12345);
      INDArray input=inOut[0];
      INDArray labels=inOut[1];
      if (labels == null) {
        System.out.println("SKIPPING TEST: " + lossFunctions[i]);
        continue;
      }
      log.info(" ***** Starting test: {} *****",testName);
      System.out.println(Arrays.toString(labels.data().asDouble()));
      System.out.println(Arrays.toString(net.output(input,false).data().asDouble()));
      System.out.println(net.score(new DataSet(input,labels)));
      boolean gradOK;
      try {
        gradOK=GradientCheckUtil.checkGradients(net,DEFAULT_EPS,DEFAULT_MAX_REL_ERROR,DEFAULT_MIN_ABS_ERROR,PRINT_RESULTS,RETURN_ON_FIRST_FAILURE,input,labels);
      }
 catch (      Exception e) {
        e.printStackTrace();
        failed.add(testName + "\t" + "EXCEPTION");
        continue;
      }
      if (gradOK) {
        passed.add(testName);
      }
 else {
        failed.add(testName);
      }
      System.out.println("\n\n");
    }
  }
  System.out.println("---- Passed ----");
  for (  String s : passed) {
    System.out.println(s);
  }
  System.out.println("---- Failed ----");
  for (  String s : failed) {
    System.out.println(s);
  }
  assertEquals("Tests failed",0,failed.size());
}
