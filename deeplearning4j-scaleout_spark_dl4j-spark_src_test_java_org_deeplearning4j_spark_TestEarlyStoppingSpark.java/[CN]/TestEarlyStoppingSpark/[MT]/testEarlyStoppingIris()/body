{
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).iterations(1).updater(Updater.SGD).weightInit(WeightInit.XAVIER).list().layer(0,new OutputLayer.Builder().nIn(4).nOut(3).lossFunction(LossFunctions.LossFunction.MCXENT).build()).pretrain(false).backprop(true).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  net.setListeners(new ScoreIterationListener(1));
  JavaRDD<DataSet> irisData=getIris();
  EarlyStoppingModelSaver<MultiLayerNetwork> saver=new InMemoryModelSaver<>();
  EarlyStoppingConfiguration<MultiLayerNetwork> esConf=new EarlyStoppingConfiguration.Builder<MultiLayerNetwork>().epochTerminationConditions(new MaxEpochsTerminationCondition(5)).iterationTerminationConditions(new MaxTimeIterationTerminationCondition(1,TimeUnit.MINUTES)).scoreCalculator(new SparkDataSetLossCalculator(irisData,true,sc.sc())).modelSaver(saver).build();
  IEarlyStoppingTrainer<MultiLayerNetwork> trainer=new SparkEarlyStoppingTrainer(getContext().sc(),new ParameterAveragingTrainingMaster.Builder(irisBatchSize()).saveUpdater(true).averagingFrequency(1).build(),esConf,net,irisData);
  EarlyStoppingResult<MultiLayerNetwork> result=trainer.fit();
  System.out.println(result);
  assertEquals(5,result.getTotalEpochs());
  assertEquals(EarlyStoppingResult.TerminationReason.EpochTerminationCondition,result.getTerminationReason());
  Map<Integer,Double> scoreVsIter=result.getScoreVsEpoch();
  assertEquals(5,scoreVsIter.size());
  String expDetails=esConf.getEpochTerminationConditions().get(0).toString();
  assertEquals(expDetails,result.getTerminationDetails());
  MultiLayerNetwork out=result.getBestModel();
  assertNotNull(out);
  MultiLayerNetwork bestNetwork=result.getBestModel();
  double score=bestNetwork.score(new IrisDataSetIterator(150,150).next());
  assertEquals(result.getBestModelScore(),score,1e-3);
}
