{
  Nd4j.getRandom().setSeed(12345);
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().seed(12345).optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).iterations(1).updater(Updater.SGD).learningRate(1e-6).weightInit(WeightInit.XAVIER).list(1).layer(0,new OutputLayer.Builder().nIn(4).nOut(3).lossFunction(LossFunctions.LossFunction.MCXENT).build()).pretrain(false).backprop(true).build();
  MultiLayerNetwork net=new MultiLayerNetwork(conf);
  net.setListeners(new ScoreIterationListener(1));
  JavaRDD<DataSet> irisData=getIris();
  EarlyStoppingModelSaver saver=new InMemoryModelSaver();
  EarlyStoppingConfiguration esConf=new EarlyStoppingConfiguration.Builder().epochTerminationConditions(new MaxEpochsTerminationCondition(10000)).iterationTerminationConditions(new MaxTimeIterationTerminationCondition(3,TimeUnit.SECONDS),new MaxScoreIterationTerminationCondition(7.5)).scoreCalculator(new SparkDataSetLossCalculator(irisData,true,sc)).modelSaver(saver).build();
  IEarlyStoppingTrainer trainer=new SparkEarlyStoppingTrainer(getContext(),esConf,net,irisData,150);
  long startTime=System.currentTimeMillis();
  EarlyStoppingResult result=trainer.fit();
  long endTime=System.currentTimeMillis();
  int durationSeconds=(int)(endTime - startTime) / 1000;
  assertTrue(durationSeconds >= 3);
  assertTrue(durationSeconds <= 9);
  assertEquals(EarlyStoppingResult.TerminationReason.IterationTerminationCondition,result.getTerminationReason());
  String expDetails=new MaxTimeIterationTerminationCondition(3,TimeUnit.SECONDS).toString();
  assertEquals(expDetails,result.getTerminationDetails());
}
