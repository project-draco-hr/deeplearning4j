{
  InputStream is=new ClassPathResource("sentiment-milliontweets.csv").getInputStream();
  LabelAwareSentenceIterator lineIter=new LabelAwareListSentenceIterator(is,",",1,3);
  lineIter.setPreProcessor(new SentencePreProcessor(){
    @Override public String preProcess(    String sentence){
      String base=new InputHomogenization(sentence).transform();
      base=StringUtils.normalizeSpace(base.replaceAll("@.*",""));
      return base;
    }
  }
);
  TokenizerFactory tokenizerFactory=new UimaTokenizerFactory();
  File wordVectors=new File("tweet-wordvectors.ser");
  Word2Vec vec=wordVectors.exists() ? (Word2Vec)SerializationUtils.readObject(wordVectors) : new Word2Vec(tokenizerFactory,lineIter,5);
  if (!wordVectors.exists()) {
    vec.train();
    SerializationUtils.saveObject(vec,wordVectors);
  }
  log.info("Initialized word vectors of size " + vec.getLayerSize());
  vec.setTokenizerFactory(tokenizerFactory);
  lineIter.reset();
  RNTN r=new RNTN.Builder().setActivationFunction(Activations.tanh()).setNumHidden(vec.getLayerSize()).setFeatureVectors(vec).build();
  tokenizerFactory=new UimaTokenizerFactory(false);
  TreeVectorizer vectorizer=new TreeVectorizer();
  Iterator<List<Tree>> treeIter=new TreeIterator(lineIter,Arrays.asList("0","1","2"),vectorizer,10);
  while (treeIter.hasNext()) {
    List<Tree> trees=treeIter.next();
    if (trees.isEmpty())     continue;
    for (int i=0; i < 100; i++) {
      r.train(trees);
      RNTNEval eval=new RNTNEval();
      log.info("Value for batch " + r.getValue() + " at iteration "+ i);
      eval.eval(r,trees);
      log.info("Eval stats " + eval.stats());
    }
  }
}
