{
  InputStream is=new ClassPathResource("sentiment-milliontweets.csv").getInputStream();
  LabelAwareSentenceIterator lineIter=new LabelAwareListSentenceIterator(is,",",1,3);
  lineIter.setPreProcessor(new SentencePreProcessor(){
    @Override public String preProcess(    String sentence){
      String base=new InputHomogenization(sentence).transform();
      base=StringUtils.normalizeSpace(base.replaceAll("@.*",""));
      return base;
    }
  }
);
  TokenizerFactory tokenizerFactory=new UimaTokenizerFactory();
  File wordVectors=new File("tweet-wordvectors.ser");
  Word2Vec vec=wordVectors.exists() ? (Word2Vec)SerializationUtils.readObject(wordVectors) : new Word2Vec(tokenizerFactory,lineIter,5);
  if (!wordVectors.exists())   vec.train();
  log.info("Initialized word vectors of size " + vec.getLayerSize());
  vec.setTokenizerFactory(tokenizerFactory);
  lineIter.reset();
  RNTN r=new RNTN.Builder().setActivationFunction(Activations.hardTanh()).setNumHidden(50).setFeatureVectors(vec).setCombineClassification(false).build();
  tokenizerFactory=new UimaTokenizerFactory(false);
  TreeVectorizer vectorizer=new TreeVectorizer();
  while (lineIter.hasNext()) {
    String sentence=lineIter.nextSentence();
    List<Tree> trees=vectorizer.getTreesWithLabels(sentence,lineIter.currentLabel(),Arrays.asList("0","1","2"));
    if (trees.isEmpty())     continue;
    r.train(trees);
    RNTNEval eval=new RNTNEval();
    eval.eval(r,trees);
    log.info("Eval stats " + eval.stats());
  }
}
