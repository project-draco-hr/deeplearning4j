{
  MultiLayerConfiguration conf=new NeuralNetConfiguration.Builder().learningRate(0.1).list().layer(0,new DenseLayer.Builder().nIn(10).nOut(10).build()).layer(1,new CustomLayer(3.14159)).layer(2,new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT).nIn(10).nOut(10).build()).pretrain(false).backprop(true).build();
  ParameterAveragingTrainingMaster tm=new ParameterAveragingTrainingMaster.Builder(1).averagingFrequency(2).batchSizePerWorker(5).saveUpdater(true).workerPrefetchNumBatches(0).build();
  SparkDl4jMultiLayer net=new SparkDl4jMultiLayer(sc,conf,tm);
  List<DataSet> testData=new ArrayList<>();
  Random r=new Random(12345);
  for (int i=0; i < 200; i++) {
    INDArray f=Nd4j.rand(1,10);
    INDArray l=Nd4j.zeros(1,10);
    l.putScalar(0,r.nextInt(10),1.0);
    testData.add(new DataSet(f,l));
  }
  JavaRDD<DataSet> rdd=sc.parallelize(testData);
  net.fit(rdd);
}
