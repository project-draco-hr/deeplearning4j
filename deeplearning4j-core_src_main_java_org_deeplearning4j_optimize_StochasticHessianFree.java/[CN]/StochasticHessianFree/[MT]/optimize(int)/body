{
  myName=Thread.currentThread().getName();
  if (converged)   return true;
  score=network.score();
  xi=optimizable.getParameters();
  BaseMultiLayerNetwork revert=network.clone();
  for (int i=0; i < 1000; i++) {
    Pair<DoubleMatrix,DoubleMatrix> backPropGradient=network.getBackPropGradient2();
    gradient=backPropGradient.getFirst().neg();
    preCon=backPropGradient.getSecond();
    if (ch == null)     setup();
    ch.muli(pi);
    Triple<DoubleMatrix,List<DoubleMatrix>,DoubleMatrix> cg=runConjugateGradient(numIterations);
    p=cg.getFirst();
    Pair<DoubleMatrix,Double> cgBackTrack=cgBackTrack(cg.getFirst(),cg.getSecond());
    p=cgBackTrack.getFirst();
    double rho=network.reductionRatio(cgBackTrack.getFirst(),network.score(),cgBackTrack.getSecond(),gradient);
    DoubleMatrix revertParams=xi.dup();
    double newScore=network.score(xi);
    try {
      step=lineSearch(newScore,ch);
      network.dampingUpdate(rho,boost,decrease);
      xi.addi(p.mul(f * step));
    }
 catch (    Exception e) {
      log.warn("Rejected update; continuing");
    }
    newScore=network.score(xi);
    if (newScore < score) {
      score=newScore;
      revert=network.clone();
      network.setParameters(xi.dup());
      log.info("New score " + score);
    }
 else {
      xi=revertParams;
      network.update(revert);
      log.info("Reverting to score " + score + " from  "+ newScore);
    }
  }
  return true;
}
