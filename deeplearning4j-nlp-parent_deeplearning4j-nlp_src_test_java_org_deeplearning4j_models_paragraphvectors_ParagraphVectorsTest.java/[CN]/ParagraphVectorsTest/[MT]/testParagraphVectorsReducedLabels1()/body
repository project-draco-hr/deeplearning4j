{
  ClassPathResource resource=new ClassPathResource("/labeled");
  File file=resource.getFile();
  LabelAwareIterator iter=new FileLabelAwareIterator.Builder().addSourceFolder(file).build();
  TokenizerFactory t=new DefaultTokenizerFactory();
  ParagraphVectors vec=new ParagraphVectors.Builder().minWordFrequency(1).epochs(3).layerSize(100).stopWords(new ArrayList<String>()).windowSize(5).iterate(iter).tokenizerFactory(t).build();
  vec.fit();
  INDArray w1=vec.lookupTable().vector("I");
  INDArray w2=vec.lookupTable().vector("am");
  INDArray w3=vec.lookupTable().vector("sad.");
  INDArray words=Nd4j.create(3,vec.lookupTable().layerSize());
  words.putRow(0,w1);
  words.putRow(1,w2);
  words.putRow(2,w3);
  INDArray mean=words.isMatrix() ? words.mean(0) : words;
  log.info("Mean" + Arrays.toString(mean.dup().data().asDouble()));
  log.info("Array" + Arrays.toString(vec.lookupTable().vector("negative").dup().data().asDouble()));
  double simN=Transforms.cosineSim(mean,vec.lookupTable().vector("negative"));
  log.info("Similarity negative: " + simN);
  double simP=Transforms.cosineSim(mean,vec.lookupTable().vector("neutral"));
  log.info("Similarity neutral: " + simP);
  double simV=Transforms.cosineSim(mean,vec.lookupTable().vector("positive"));
  log.info("Similarity positive: " + simV);
}
