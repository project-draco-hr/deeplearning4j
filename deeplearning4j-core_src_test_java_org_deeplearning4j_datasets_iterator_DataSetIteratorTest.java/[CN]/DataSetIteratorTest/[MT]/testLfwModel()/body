{
  final int numRows=28;
  final int numColumns=28;
  int numChannels=3;
  int outputNum=LFWLoader.SUB_NUM_LABELS;
  int numSamples=4;
  int batchSize=2;
  int iterations=1;
  int seed=123;
  int listenerFreq=iterations;
  LFWDataSetIterator lfw=new LFWDataSetIterator(batchSize,numSamples,new int[]{numRows,numColumns,numChannels},outputNum,true);
  MultiLayerConfiguration.Builder builder=new NeuralNetConfiguration.Builder().seed(seed).iterations(iterations).gradientNormalization(GradientNormalization.RenormalizeL2PerLayer).optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).list(3).layer(0,new ConvolutionLayer.Builder(10,10).nIn(numChannels).nOut(6).weightInit(WeightInit.XAVIER).activation("relu").build()).layer(1,new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX,new int[]{2,2}).build()).layer(2,new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD).nOut(outputNum).weightInit(WeightInit.XAVIER).activation("softmax").build()).backprop(true).pretrain(false);
  new ConvolutionLayerSetup(builder,numRows,numColumns,numChannels);
  MultiLayerNetwork model=new MultiLayerNetwork(builder.build());
  model.init();
  model.setListeners(Arrays.asList((IterationListener)new ScoreIterationListener(listenerFreq)));
  model.fit(lfw.next());
  DataSet dataTest=lfw.next();
  INDArray output=model.output(dataTest.getFeatureMatrix());
  Evaluation eval=new Evaluation(outputNum);
  eval.eval(dataTest.getLabels(),output);
  System.out.println(eval.stats());
}
