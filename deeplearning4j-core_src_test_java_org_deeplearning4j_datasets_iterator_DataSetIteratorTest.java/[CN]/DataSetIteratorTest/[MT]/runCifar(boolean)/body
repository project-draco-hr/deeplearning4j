{
  final int height=32;
  final int width=32;
  int channels=3;
  int outputNum=CifarLoader.NUM_LABELS;
  int numSamples=110;
  int batchSize=5;
  int iterations=1;
  int seed=123;
  int listenerFreq=iterations;
  CifarDataSetIterator cifar=new CifarDataSetIterator(batchSize,numSamples,new int[]{height,width,channels},preProcessCifar,true);
  MultiLayerConfiguration.Builder builder=new NeuralNetConfiguration.Builder().seed(seed).iterations(iterations).gradientNormalization(GradientNormalization.RenormalizeL2PerLayer).optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).list().layer(0,new ConvolutionLayer.Builder(5,5).nIn(channels).nOut(6).weightInit(WeightInit.XAVIER).activation("relu").build()).layer(1,new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX,new int[]{2,2}).build()).layer(2,new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD).nOut(outputNum).weightInit(WeightInit.XAVIER).activation("softmax").build()).backprop(true).pretrain(false).setInputType(InputType.convolutionalFlat(height,width,channels));
  MultiLayerNetwork model=new MultiLayerNetwork(builder.build());
  model.init();
  model.setListeners(Arrays.asList((IterationListener)new ScoreIterationListener(listenerFreq)));
  model.fit(cifar);
  cifar.test(numSamples);
  Evaluation eval=new Evaluation(cifar.getLabels());
  while (cifar.hasNext()) {
    DataSet testDS=cifar.next(batchSize);
    INDArray output=model.output(testDS.getFeatureMatrix());
    eval.eval(testDS.getLabels(),output);
  }
  System.out.println(eval.stats(true));
}
